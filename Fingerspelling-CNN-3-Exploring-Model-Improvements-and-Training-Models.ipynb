{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving or loading the model as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"model_3_0\") creates a folder with the same name as the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_2 = load_model(\"model_2_after_15_epochs\") loads a model from this folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Baseline Model](#Baseline-Model)\n",
    "\n",
    "[Trying Model Improvements](#Trying-Model-Improvements)\n",
    "(sub-entries) [Viewing image](#Viewing-image), [Disabling the datagen's shuffle feature](#Disabling-the-datagen's-shuffle-feature), [Perhaps that warning when importing MobileNetV2 is actually not all bark and no bite](#Perhaps-that-warning-when-importing-MobileNetV2-is-actually-not-all-bark-and-no-bite), \n",
    "\n",
    "[Generating New Baseline Model](#Generating-New-Baseline-Model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function imports a directory full of subdirectories full of photos, with each subdirectory named after the class of its stored photos.\n",
    "\n",
    "train_data/ \n",
    "\n",
    "     |\n",
    "     V     \n",
    "     |\n",
    "     |\n",
    "      >  A/ -> A_1, A_2, A_3, etc.\n",
    "     |\n",
    "      >  B/ -> B_1, B_2, B_3, etc.\n",
    "     |  \n",
    "      >  C/ -> C_1, C_2, C_3, etc.\n",
    "     |  \n",
    "      >  D/ -> D_1, D_2, D_3, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(image_size, path, preprocess_func=None, split_off_for_val=0.0, split_segment = None, shuf = True):\n",
    "    this_datagen = ImageDataGenerator(preprocessing_function = preprocess_func, validation_split = split_off_for_val)\n",
    "    #  note: ImageDataGenerator does not appear to have a parameter for random seeds. Be wary of train/val overlap\n",
    "    #  note: train/val/test split does not currently work\n",
    "    this_generator = this_datagen.flow_from_directory(path, \n",
    "                                                     target_size=image_size,\n",
    "                                                     subset = split_segment, #  None|'training'|'validation'\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=80,\n",
    "                                                     class_mode='categorical',\n",
    "                                                     shuffle=shuf)\n",
    "    return this_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the split functionality did not work, I split the data manually into train/validation/test sets.\n",
    "\n",
    "3000 images per class became:\n",
    "\n",
    "900 test + 630 val + 1470 train\n",
    "\n",
    "87000 images total became:\n",
    "\n",
    "26100 test + 18270 val + 42630 train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42630 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x21e225e1df0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data_generator(image_size = [80,80],\n",
    "                            path = 'data/grassnoted split/asl_alphabet_train',\n",
    "                           )\n",
    "train_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18270 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x21e298cf760>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = data_generator(image_size = [80,80], \n",
    "                                 path = 'data/grassnoted split/asl_alphabet_validation',\n",
    "                                )\n",
    "validation_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26100 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x21e1f9cd880>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = data_generator(image_size = [80,80],\n",
    "                           path = 'data/grassnoted split/asl_alphabet_test',\n",
    "                          )\n",
    "test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing MobileNetV2 for use in transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "experienced_model = MobileNetV2(weights='imagenet', include_top=False, input_shape = (80,80,3))\n",
    "#input shape minimum is 32x32\n",
    "#this warning is all bark and no bite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining an untrained neural network to attach to the end of MobileNetV2 in order to make predictions in our current problem space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the output of this base_model to a variable:\n",
    "base_model_out = experienced_model.output\n",
    "\n",
    "\n",
    "\n",
    "# Add a pooling layer:\n",
    "base_model_out = GlobalAveragePooling2D()(base_model_out)\n",
    "\n",
    "# using a softmax base_model_out activation function:\n",
    "preds = Dense(29, activation='softmax')(base_model_out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate our final model, where we specify what are the inputs and \n",
    "# the outputs will look like\n",
    "model = Model(inputs = experienced_model.input, \n",
    "              outputs = preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the number of nodes in the topless MobileNetV2 by looking at the index of the pooling layer. These should be locked in order to preserve their weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_9\n",
      "1 Conv1\n",
      "2 bn_Conv1\n",
      "3 Conv1_relu\n",
      "4 expanded_conv_depthwise\n",
      "5 expanded_conv_depthwise_BN\n",
      "6 expanded_conv_depthwise_relu\n",
      "7 expanded_conv_project\n",
      "8 expanded_conv_project_BN\n",
      "9 block_1_expand\n",
      "10 block_1_expand_BN\n",
      "11 block_1_expand_relu\n",
      "12 block_1_pad\n",
      "13 block_1_depthwise\n",
      "14 block_1_depthwise_BN\n",
      "15 block_1_depthwise_relu\n",
      "16 block_1_project\n",
      "17 block_1_project_BN\n",
      "18 block_2_expand\n",
      "19 block_2_expand_BN\n",
      "20 block_2_expand_relu\n",
      "21 block_2_depthwise\n",
      "22 block_2_depthwise_BN\n",
      "23 block_2_depthwise_relu\n",
      "24 block_2_project\n",
      "25 block_2_project_BN\n",
      "26 block_2_add\n",
      "27 block_3_expand\n",
      "28 block_3_expand_BN\n",
      "29 block_3_expand_relu\n",
      "30 block_3_pad\n",
      "31 block_3_depthwise\n",
      "32 block_3_depthwise_BN\n",
      "33 block_3_depthwise_relu\n",
      "34 block_3_project\n",
      "35 block_3_project_BN\n",
      "36 block_4_expand\n",
      "37 block_4_expand_BN\n",
      "38 block_4_expand_relu\n",
      "39 block_4_depthwise\n",
      "40 block_4_depthwise_BN\n",
      "41 block_4_depthwise_relu\n",
      "42 block_4_project\n",
      "43 block_4_project_BN\n",
      "44 block_4_add\n",
      "45 block_5_expand\n",
      "46 block_5_expand_BN\n",
      "47 block_5_expand_relu\n",
      "48 block_5_depthwise\n",
      "49 block_5_depthwise_BN\n",
      "50 block_5_depthwise_relu\n",
      "51 block_5_project\n",
      "52 block_5_project_BN\n",
      "53 block_5_add\n",
      "54 block_6_expand\n",
      "55 block_6_expand_BN\n",
      "56 block_6_expand_relu\n",
      "57 block_6_pad\n",
      "58 block_6_depthwise\n",
      "59 block_6_depthwise_BN\n",
      "60 block_6_depthwise_relu\n",
      "61 block_6_project\n",
      "62 block_6_project_BN\n",
      "63 block_7_expand\n",
      "64 block_7_expand_BN\n",
      "65 block_7_expand_relu\n",
      "66 block_7_depthwise\n",
      "67 block_7_depthwise_BN\n",
      "68 block_7_depthwise_relu\n",
      "69 block_7_project\n",
      "70 block_7_project_BN\n",
      "71 block_7_add\n",
      "72 block_8_expand\n",
      "73 block_8_expand_BN\n",
      "74 block_8_expand_relu\n",
      "75 block_8_depthwise\n",
      "76 block_8_depthwise_BN\n",
      "77 block_8_depthwise_relu\n",
      "78 block_8_project\n",
      "79 block_8_project_BN\n",
      "80 block_8_add\n",
      "81 block_9_expand\n",
      "82 block_9_expand_BN\n",
      "83 block_9_expand_relu\n",
      "84 block_9_depthwise\n",
      "85 block_9_depthwise_BN\n",
      "86 block_9_depthwise_relu\n",
      "87 block_9_project\n",
      "88 block_9_project_BN\n",
      "89 block_9_add\n",
      "90 block_10_expand\n",
      "91 block_10_expand_BN\n",
      "92 block_10_expand_relu\n",
      "93 block_10_depthwise\n",
      "94 block_10_depthwise_BN\n",
      "95 block_10_depthwise_relu\n",
      "96 block_10_project\n",
      "97 block_10_project_BN\n",
      "98 block_11_expand\n",
      "99 block_11_expand_BN\n",
      "100 block_11_expand_relu\n",
      "101 block_11_depthwise\n",
      "102 block_11_depthwise_BN\n",
      "103 block_11_depthwise_relu\n",
      "104 block_11_project\n",
      "105 block_11_project_BN\n",
      "106 block_11_add\n",
      "107 block_12_expand\n",
      "108 block_12_expand_BN\n",
      "109 block_12_expand_relu\n",
      "110 block_12_depthwise\n",
      "111 block_12_depthwise_BN\n",
      "112 block_12_depthwise_relu\n",
      "113 block_12_project\n",
      "114 block_12_project_BN\n",
      "115 block_12_add\n",
      "116 block_13_expand\n",
      "117 block_13_expand_BN\n",
      "118 block_13_expand_relu\n",
      "119 block_13_pad\n",
      "120 block_13_depthwise\n",
      "121 block_13_depthwise_BN\n",
      "122 block_13_depthwise_relu\n",
      "123 block_13_project\n",
      "124 block_13_project_BN\n",
      "125 block_14_expand\n",
      "126 block_14_expand_BN\n",
      "127 block_14_expand_relu\n",
      "128 block_14_depthwise\n",
      "129 block_14_depthwise_BN\n",
      "130 block_14_depthwise_relu\n",
      "131 block_14_project\n",
      "132 block_14_project_BN\n",
      "133 block_14_add\n",
      "134 block_15_expand\n",
      "135 block_15_expand_BN\n",
      "136 block_15_expand_relu\n",
      "137 block_15_depthwise\n",
      "138 block_15_depthwise_BN\n",
      "139 block_15_depthwise_relu\n",
      "140 block_15_project\n",
      "141 block_15_project_BN\n",
      "142 block_15_add\n",
      "143 block_16_expand\n",
      "144 block_16_expand_BN\n",
      "145 block_16_expand_relu\n",
      "146 block_16_depthwise\n",
      "147 block_16_depthwise_BN\n",
      "148 block_16_depthwise_relu\n",
      "149 block_16_project\n",
      "150 block_16_project_BN\n",
      "151 Conv_1\n",
      "152 Conv_1_bn\n",
      "153 out_relu\n",
      "154 global_average_pooling2d_8\n",
      "155 dense_32\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that layer 154 is where our added layers begin. We will lock all layers above 154 and make them untrainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_average_pooling2d_8\n",
      "dense_32\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:154]:\n",
    "    layer.trainable=False\n",
    "    \n",
    "for layer in model.layers[154:]:\n",
    "    print(layer.name)\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size_train = train_data.n//train_data.batch_size + 1\n",
    "\n",
    "# 'train_data.n' = 60,900 images\n",
    "# 'train_generator.batch_size' = 80 images per batch\n",
    "# 'step_size_train' = 762  (!needs to be int)\n",
    "step_size_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', #loss function\n",
    "                  optimizer = 'Adam',\n",
    "                  metrics = ['accuracy']) #value to maximize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533/533 [==============================] - 231s 426ms/step - loss: 1.9089 - accuracy: 0.4958 - val_loss: 2.4178 - val_accuracy: 0.3754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22101aca430>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = train_data, validation_data = validation_data, steps_per_epoch = step_size_train, epochs = 1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Model Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(model.history.history['accuracy'], marker='o', label='training accuracy')\n",
    "plt.plot(model.history.history['val_accuracy'], marker='o', label='validation accuracy')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Acc|Valid Acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying Model Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing image\n",
    "TODO\n",
    "\n",
    "I do not know how to view images from the imagedatagenerator.\n",
    "However, with an accuracy of greater than 1/29, it at least is not guessing the same value for all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This and many other troubleshooting steps are based on the guide [here](https://www.kdnuggets.com/2017/08/37-reasons-neural-network-not-working.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disabling the datagen's shuffle feature\n",
    "[Rumor has it](https://stackoverflow.com/questions/41695844/keras-showing-images-from-data-generator) from Gerry P., this is used \"to maintain a correlation between the file and the associated prediction.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42630 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x2206fcabfd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data_generator(image_size = [80,80],\n",
    "                            path = 'data/grassnoted split/asl_alphabet_train',\n",
    "                            shuf = False\n",
    "                           )\n",
    "train_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18270 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x2206fcabf40>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = data_generator(image_size = [80,80], \n",
    "                                 path = 'data/grassnoted split/asl_alphabet_validation',\n",
    "                                 shuf = False\n",
    "                                )\n",
    "validation_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26100 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x2206fcad550>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = data_generator(image_size = [80,80],\n",
    "                           path = 'data/grassnoted split/asl_alphabet_test',\n",
    "                           shuf = False\n",
    "                          )\n",
    "test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', #loss function\n",
    "                  optimizer = 'Adam',\n",
    "                  metrics = ['accuracy']) #value to maximize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h\\.conda\\envs\\deeplearningcopy\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "533/533 [==============================] - 205s 376ms/step - loss: 1.2749 - accuracy: 0.6604 - val_loss: 3.7137 - val_accuracy: 0.2925\n",
      "Epoch 2/4\n",
      "533/533 [==============================] - 190s 357ms/step - loss: 1.1664 - accuracy: 0.6588 - val_loss: 3.5937 - val_accuracy: 0.3351\n",
      "Epoch 3/4\n",
      "533/533 [==============================] - 184s 344ms/step - loss: 1.1234 - accuracy: 0.6880 - val_loss: 3.3541 - val_accuracy: 0.3335\n",
      "Epoch 4/4\n",
      "533/533 [==============================] - 193s 362ms/step - loss: 1.1090 - accuracy: 0.6847 - val_loss: 4.2103 - val_accuracy: 0.3124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2206fff2fd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_data, validation_data = validation_data, steps_per_epoch = step_size_train, epochs = 4, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Model Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(model.history.history['accuracy'], marker='o', label='training accuracy')\n",
    "plt.plot(model.history.history['val_accuracy'], marker='o', label='validation accuracy')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Acc|Valid Acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears to be less effective for both training and validation accuracies.\n",
    "Returing to shuffle = True going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perhaps that warning when importing MobileNetV2 is actually not all bark and no bite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the input images are 200x200, it's possible to import and use images that are larger than 80x80. A limiting factor will be found if my kernel crashes.\n",
    "\n",
    "Image shapes it prefers are \\[96, 128, 160, 192, 224\\] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42630 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x2207a977430>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data_generator(image_size = [96,96],\n",
    "                            path = 'data/grassnoted split/asl_alphabet_train',\n",
    "                           )\n",
    "train_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18270 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x2207a96f9d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = data_generator(image_size = [96,96], \n",
    "                                 path = 'data/grassnoted split/asl_alphabet_validation',\n",
    "                                )\n",
    "validation_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26100 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x2207a9776d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = data_generator(image_size = [96,96],\n",
    "                           path = 'data/grassnoted split/asl_alphabet_test',\n",
    "                          )\n",
    "test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing MobileNetV2 for use in transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "experienced_model = MobileNetV2(weights='imagenet', include_top=False, input_shape = (96,96,3))\n",
    "#input shape minimum is 32x32\n",
    "#this warning is all bark and no bite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining an untrained neural network to attach to the end of MobileNetV2 in order to make predictions in our current problem space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the output of this base_model to a variable:\n",
    "base_model_out = experienced_model.output\n",
    "\n",
    "\n",
    "\n",
    "# Add a pooling layer:\n",
    "base_model_out = GlobalAveragePooling2D()(base_model_out)\n",
    "\n",
    "# using a softmax base_model_out activation function:\n",
    "preds = Dense(29, activation='softmax')(base_model_out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate our final model, where we specify what are the inputs and \n",
    "# the outputs will look like\n",
    "model = Model(inputs = experienced_model.input, \n",
    "              outputs = preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the number of nodes in the topless MobileNetV2 by looking at the index of the pooling layer. These should be locked in order to preserve their weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_4\n",
      "1 Conv1\n",
      "2 bn_Conv1\n",
      "3 Conv1_relu\n",
      "4 expanded_conv_depthwise\n",
      "5 expanded_conv_depthwise_BN\n",
      "6 expanded_conv_depthwise_relu\n",
      "7 expanded_conv_project\n",
      "8 expanded_conv_project_BN\n",
      "9 block_1_expand\n",
      "10 block_1_expand_BN\n",
      "11 block_1_expand_relu\n",
      "12 block_1_pad\n",
      "13 block_1_depthwise\n",
      "14 block_1_depthwise_BN\n",
      "15 block_1_depthwise_relu\n",
      "16 block_1_project\n",
      "17 block_1_project_BN\n",
      "18 block_2_expand\n",
      "19 block_2_expand_BN\n",
      "20 block_2_expand_relu\n",
      "21 block_2_depthwise\n",
      "22 block_2_depthwise_BN\n",
      "23 block_2_depthwise_relu\n",
      "24 block_2_project\n",
      "25 block_2_project_BN\n",
      "26 block_2_add\n",
      "27 block_3_expand\n",
      "28 block_3_expand_BN\n",
      "29 block_3_expand_relu\n",
      "30 block_3_pad\n",
      "31 block_3_depthwise\n",
      "32 block_3_depthwise_BN\n",
      "33 block_3_depthwise_relu\n",
      "34 block_3_project\n",
      "35 block_3_project_BN\n",
      "36 block_4_expand\n",
      "37 block_4_expand_BN\n",
      "38 block_4_expand_relu\n",
      "39 block_4_depthwise\n",
      "40 block_4_depthwise_BN\n",
      "41 block_4_depthwise_relu\n",
      "42 block_4_project\n",
      "43 block_4_project_BN\n",
      "44 block_4_add\n",
      "45 block_5_expand\n",
      "46 block_5_expand_BN\n",
      "47 block_5_expand_relu\n",
      "48 block_5_depthwise\n",
      "49 block_5_depthwise_BN\n",
      "50 block_5_depthwise_relu\n",
      "51 block_5_project\n",
      "52 block_5_project_BN\n",
      "53 block_5_add\n",
      "54 block_6_expand\n",
      "55 block_6_expand_BN\n",
      "56 block_6_expand_relu\n",
      "57 block_6_pad\n",
      "58 block_6_depthwise\n",
      "59 block_6_depthwise_BN\n",
      "60 block_6_depthwise_relu\n",
      "61 block_6_project\n",
      "62 block_6_project_BN\n",
      "63 block_7_expand\n",
      "64 block_7_expand_BN\n",
      "65 block_7_expand_relu\n",
      "66 block_7_depthwise\n",
      "67 block_7_depthwise_BN\n",
      "68 block_7_depthwise_relu\n",
      "69 block_7_project\n",
      "70 block_7_project_BN\n",
      "71 block_7_add\n",
      "72 block_8_expand\n",
      "73 block_8_expand_BN\n",
      "74 block_8_expand_relu\n",
      "75 block_8_depthwise\n",
      "76 block_8_depthwise_BN\n",
      "77 block_8_depthwise_relu\n",
      "78 block_8_project\n",
      "79 block_8_project_BN\n",
      "80 block_8_add\n",
      "81 block_9_expand\n",
      "82 block_9_expand_BN\n",
      "83 block_9_expand_relu\n",
      "84 block_9_depthwise\n",
      "85 block_9_depthwise_BN\n",
      "86 block_9_depthwise_relu\n",
      "87 block_9_project\n",
      "88 block_9_project_BN\n",
      "89 block_9_add\n",
      "90 block_10_expand\n",
      "91 block_10_expand_BN\n",
      "92 block_10_expand_relu\n",
      "93 block_10_depthwise\n",
      "94 block_10_depthwise_BN\n",
      "95 block_10_depthwise_relu\n",
      "96 block_10_project\n",
      "97 block_10_project_BN\n",
      "98 block_11_expand\n",
      "99 block_11_expand_BN\n",
      "100 block_11_expand_relu\n",
      "101 block_11_depthwise\n",
      "102 block_11_depthwise_BN\n",
      "103 block_11_depthwise_relu\n",
      "104 block_11_project\n",
      "105 block_11_project_BN\n",
      "106 block_11_add\n",
      "107 block_12_expand\n",
      "108 block_12_expand_BN\n",
      "109 block_12_expand_relu\n",
      "110 block_12_depthwise\n",
      "111 block_12_depthwise_BN\n",
      "112 block_12_depthwise_relu\n",
      "113 block_12_project\n",
      "114 block_12_project_BN\n",
      "115 block_12_add\n",
      "116 block_13_expand\n",
      "117 block_13_expand_BN\n",
      "118 block_13_expand_relu\n",
      "119 block_13_pad\n",
      "120 block_13_depthwise\n",
      "121 block_13_depthwise_BN\n",
      "122 block_13_depthwise_relu\n",
      "123 block_13_project\n",
      "124 block_13_project_BN\n",
      "125 block_14_expand\n",
      "126 block_14_expand_BN\n",
      "127 block_14_expand_relu\n",
      "128 block_14_depthwise\n",
      "129 block_14_depthwise_BN\n",
      "130 block_14_depthwise_relu\n",
      "131 block_14_project\n",
      "132 block_14_project_BN\n",
      "133 block_14_add\n",
      "134 block_15_expand\n",
      "135 block_15_expand_BN\n",
      "136 block_15_expand_relu\n",
      "137 block_15_depthwise\n",
      "138 block_15_depthwise_BN\n",
      "139 block_15_depthwise_relu\n",
      "140 block_15_project\n",
      "141 block_15_project_BN\n",
      "142 block_15_add\n",
      "143 block_16_expand\n",
      "144 block_16_expand_BN\n",
      "145 block_16_expand_relu\n",
      "146 block_16_depthwise\n",
      "147 block_16_depthwise_BN\n",
      "148 block_16_depthwise_relu\n",
      "149 block_16_project\n",
      "150 block_16_project_BN\n",
      "151 Conv_1\n",
      "152 Conv_1_bn\n",
      "153 out_relu\n",
      "154 global_average_pooling2d_2\n",
      "155 dense_2\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that layer 154 is where our added layers begin. We will lock all layers above 154 and make them untrainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_average_pooling2d_2\n",
      "dense_2\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:154]:\n",
    "    layer.trainable=False\n",
    "    \n",
    "for layer in model.layers[154:]:\n",
    "    print(layer.name)\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size_train = train_data.n//train_data.batch_size + 1\n",
    "\n",
    "# 'train_data.n' = 60,900 images\n",
    "# 'train_generator.batch_size' = 80 images per batch\n",
    "# 'step_size_train' = 762  (!needs to be int)\n",
    "step_size_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', #loss function\n",
    "                  optimizer = 'Adam',\n",
    "                  metrics = ['accuracy']) #value to maximize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h\\.conda\\envs\\deeplearningcopy\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "533/533 [==============================] - 235s 436ms/step - loss: 2.0651 - accuracy: 0.4765 - val_loss: 2.4204 - val_accuracy: 0.3607\n",
      "Epoch 2/4\n",
      "533/533 [==============================] - 228s 429ms/step - loss: 0.7844 - accuracy: 0.8083 - val_loss: 2.3251 - val_accuracy: 0.4227\n",
      "Epoch 3/4\n",
      "533/533 [==============================] - 242s 454ms/step - loss: 0.5527 - accuracy: 0.8640 - val_loss: 2.3205 - val_accuracy: 0.4635\n",
      "Epoch 4/4\n",
      "533/533 [==============================] - 240s 450ms/step - loss: 0.4570 - accuracy: 0.8838 - val_loss: 2.3363 - val_accuracy: 0.4838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2207c0a39d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_data, validation_data = validation_data, steps_per_epoch = step_size_train, epochs = 4, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Model Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5FElEQVR4nO3deXwU9fnA8c9DSMgJCafcoIIgECAEUCmIIohabwXUaqG1VjyrLbX2ArW21rvWWov+sGq98MITb/FoVc4AglwCSghHuEJCQs7n98dMNpvNJrsJu9kk+7xfr31ld2Z29pmdzfeZ+c53vl9RVYwxxkSvVpEOwBhjTGRZIjDGmChnicAYY6KcJQJjjIlylgiMMSbKWSIwxpgoZ4mgCRORhSLy41Ava8JPRMaLSHYY1ttHRFREWruva93vvss24LN+KyKPH0m8pnmwRBBiIlLg9agQkSKv15fVZ12qeoaqPhnqZRtCRPq62/NIuD4jWojIOhH5iZ/pN4rI0vqsK1T73V/iUtU/q+qVR7ruAJ+pIvLrcH2GCY4lghBT1eTKB/A9cLbXtGcql2voUVoEXQHsB6aJSJvG/GARiWnMz2sET+J8n74ud+dFix8D+9y/jUYcVvZ5U1V7hOkBbAVOc5+PB7KBW4CdwNNAGvAmkItTyL4J9PB6/yLgSvf5dOBz4F532S3AGQ1cti/wKZAPfAD8A/hPgG35FpgJ7AIu8pl3LpAFHHSXm+xObw88AeS4cSzwjs9nHQoc6z7/N/BP4G3gEHAacBawwv2MbcAcn/f/APgfcMCdPx0Y6cbb2mu5C4GsWrax1s8A+rgx/hgnwe8Bfuc1P8GNez+wFpgFZNfyOT2AMqC317SBQAnQMcg4WvvZ7zHuPt8DbAau9Vl2BvCNu983Az93pycBRUAFUOA+ugFzvH8XwDnAGvc7XgQM9Pmt/wpYBeQBLwDxdfyeEt04prnbnekz/2desa4FMtzpPYFXcP5n9gIPu9N9Y/X3Pd0J/Nfd1mNr+z7q+l0DFwPLfJb7Je5vu7k+Ih5AS35QMxGUAX8F2uAUHB1wCqZEIAV40fsHRc3CvdT9B4nBKZRzAGnAsl/gFBhxOAXoQepIBMBYoBgncf0deN1r3ij3H38izhlmd2CAO+8tt0BIA2KBk73iC5QI8oAx7jrj3e9viPs6HaeAP89dvpf7z3yJ+zkdgGHuvLVUT4KvAr+sZTvr+ow+boyPuftuqPudDHTn3wV8hpP8egJfU0sicJd/H/i91+u/UJUog4nDXyK4Gljnfn574GOfZc8CjgEEOBkopKqAHe8bL16FK9AfJylPdL/jXwObgDiv3/pinATSHqeAvbqO7b8c2IHz+3wDeMhr3sXAdpxELjiFdm932ZXAAzjJKx74gW+sdXxP3wODgNbuNtT1ffj9XeP87+6jehJcAVwY6fLmiMqqSAfQkh/UTAQl1H2UNAzY7/Xa+598OrDJa16i+0M/qj7L4hSaZUCi1/z/UHcieJyqQupEnCTT2X39L+ABP+/pinOEmeZn3nQCJ4KnAny3D1Z+LnAr8Goty90CPOM+b+/+s3cNcv95f0ZlweJ9xrYYmOY+34x7JuS+voq6E8GPgPXu81ZuIXV+PeLwlwg+wqvwBSZ5L+tnvQuAG71+n3Ulgj8A873mtcIprMd7/dZ/5DX/buDROrb/A+BB9/klOEf4se7rdyvj8nnPie5yNbaH4BLB7QH2t/f34fd37c77J3Cn+3wQzllgm2B+U031YfVkjStXVQ9XvhCRRBH5l4h8JyIHcaprUuuoE99Z+URVC92nyfVcthuwz2saONUPfolIAs4R2jPuur7AKbQudRfpiXPa7Kun+zn7a1t3ANViEpHRIvKxiOSKSB7O0W/HADGAk+TOFpFkYArwmaru8LdggM+otNPreSFV3383n5i/q3vzeAXoKiIn4BTCiThnUMHG4U+dMYjIGSLypYjsE5EDwJlBrrdy3Z71qWqF+1ndvZap7bupRkR6Aqfg/qaA13CO7s9yX9f1m/pOVcuCjNmX72+qru+jrt/Uk8ClIiI4ZzbzVbW4gTE1CZYIGpf6vP4lcBwwWlXbAuPc6RLGGHYA7UUk0WtazzqWPx9oCzwiIjtFZCfOP3/lxc5tOKfXvra5n5PqZ94hnIIPABE5ys8yvt/Vs8DrQE9VbQc8StX3VFsMqOp2nKqw83H+aZ/2t1wQnxHIDqp/j73qWthNxC/hfI+XA8+raskRxlFrDO4F/pdxqgS7qGoqzjWYyvX6ft++cnCqZyrXJ+5nbQ8iLl+X45Q9b7i/p804iSCY31SvWhpaVPtN4Zz9+vJsYxDfR12/qS9xzu7H4hwQ1fWbahYsEURWCs6FqwMi0h6YHe4PVNXvgKXAHBGJE5ETgbPreMuPgXk4ddbD3McYYJiIDAH+D5ghIhNEpJWIdBeRAe5R90KcBJImIrEiUpnoVgKDRGSYiMTjnNYHkoJzhnFYREZRdUYCzpHlaSIyRURai0gHERnmNf8pnDrtITjXCBryGYHMB251t7UHcH0Q73kSmIpznci7tVBD45gP3CAiPUQkDfiN17w4nPrtXKBMRM7AqTqqtAvoICLt6lj3We5+jsU5iCnGuUBfX1cAt1H1exqG8x2cJSIdcKoifyUiI9wWPseKSG+cqrgdwF0ikiQi8SIyxl1nFjBORHq523BrgBgCfR9+f9de858CHgbKVPXzBnwHTYolgsh6EOfC4x7gS+CdRvrcy3DqW/cCf8K5oFvj1FZEugMTcOpyd3o9lrmx/lhVF+O0vngA5+LaJ1QdOV6Ocz1hHbAb+AWAqm4AbsepJ96I08IpkGuA20UkH/gjTsGEu77vcU7rf4lzIS8L52JupVfdmF5V1UMN+Ywg3IZTdbIFeI/gjhI/xfnOtqvqkhDE8RhO/fpKYDlO9RMAqpoP3OCuaz9Ocnnda/464Dlgs4gcEJFu3itW1fU41zX+jvN7PRunaXQJ9eBWhfUB/uHzm3od5+LzJar6Ik4Ln2dxGgEsANqrarn7ucfiVE9m4yRSVPV9nN/xKmAZTgu8WgXxfdT1uwZn/w6mBZwNQFUrEhPFROQFYJ2qhv2MJFJE5Fuc5oEfRDoW0/y5185247Qy2hjpeI6UnRFEIREZKSLHuKe8k3HaSy+IcFhhIyIX4tQPfxTpWEyLMRNY0hKSADjtaU30OQqn2qADzun1TFVdEdmQwkNEFgHHA5e7LV2MOSIishXnovJ5kY0kdKxqyBhjopxVDRljTJRrllVDHTt21D59+kQ6DGOMaVaWLVu2R1U7+U5vlomgT58+LF1ar956jTEm6omI3zverWrIGGOinCUCY4yJcpYIjDEmylkiMMaYKGeJwBhjolyzbDVkjDHRZMGK7dzz7npyDhTRLTWBWacfx3nDuwd+Y5AsERhjTBO2YMV2bn1lNUWl5QBsP1DEra+sBghZMrCqIWOMaWJUlbzCUjbtzudPb631JIFKRaXl3PPu+pB9np0RGGNMIyksKSM3v5jc/GL2FBR7nud6P88vZk9BCSXldfeRmHOgKGRxWSIwxpgjUFJWwd5D1QtyT0HvU8AfKimv8X4R6JDUho7JcXRKacMxnZPplNKGTslt6JTShjveXMuegprj/3RLTQjZNlgiMMYYHxUVyr7CkupH7X6O3vcUFLO/sNTvOtrGt3YK9JQ2DOmRSqfkNnRMifMU8JWP9olxtI6pvZZelWrXCAASYmOYdfpxIdteSwTGmKigquQXl9U8avdTwO89VEJ5Rc0u+uNjW9E5JZ6OyXEc3SmJ0Ue3p1NyfLWCvWNyHB2T2xAfGxOSuCsvCFurIWOMqcXh0nK/9eyVr70L++KymvXurVsJHd2j9C5t4xncrZ3XkXv1Qj4pLgYRafRtPG9495AW/L4sERhjmpyy8gr2Hiqpu4B3X+cXl/ldR4ekOE8B36dPUrV6d+fI3fmbmhBLq1aNX7g3JZYIjDGNQlU5UFjqt2Df41Pg7ysswd/giSltnHr3jiltGNitLeMqC3bfevekOGLrqHc31VkiMMZUU5+7WFWVQyXlNevb/VTP7CkoprS8Zuke17qVpyDv2T6RjN5pNY7cO7t/E+JCU+9uqrNEYIzx8HcX669fWsV/v91Dz7REvxdWfW92AmgleKpeOqW0YcBRKXT0c+TeKaUNKW1aR6Te3VSxRGBMFCstr2DLnkNs2JXPhl0FzP30Ww6XVr+gWlJewYtLswFITYz1FObDe6XWKNgrC/+0xDhiorzevTmxRGBMFCgrr2Dr3kI2ugX+ht35bNyVz5Y9hzzVNSL4rZcHEGD9n84grrXVu7dElgiMaUHKK5Tv9xWyYVd+VaG/K5/NuYc8XRaIQM+0RPp3SWbCwC7075JMv84pHNs5mQn3fcJ2P10XdEtNsCTQglkiMKYZqqhQsvcXsX5XfrVC/9vcgmpt5bunJtC/SzIn9+9E/y4p9O+SwjGdk0iM8/+vP+v048J+F6tpeiwRGNOEVVQo2w8UsXF31dH9xl0FbNpdUK2w7tYunn5dUhhzbAf6uQX+sZ2TSW5Tv3/xxriL1TQ9YU0EIjIZ+BsQAzyuqnf5zG8H/Afo5cZyr6o+Ec6YjGmKVJUdeYc9Bf169yh/4+4CCr06KuvStg39u6RwyaheTpVOlxT6dUmmbXxsyGIJ912spukJWyIQkRjgH8BEIBtYIiKvq+par8WuBdaq6tki0glYLyLPqGrNrvaMaQFUlV0Hi91WOk6hv2F3Ppt2FVS7Q7Zjchv6d0lmSmZP+nVJ5rguKfTrnEK7xNAV+MZUCucZwShgk6puBhCR54FzAe9EoECKOI2Ik4F9gP/7xY1pRlSV3IJip6B36+83uoX/wcNVP/H2SXH075LM+RndnSqdzsn075JCWlJcBKM30SaciaA7sM3rdTYw2meZh4HXgRwgBZiqqn5HYxCRq4CrAHr16hXyYI1pqL0FxU5Bv9sp6DfsdI7yD3h1T5yaGEv/zimcPbQb/d3qnP5dUuiY3CaCkRvjCGci8Hc3iW8r5dOBLOBU4BjgfRH5TFUP1nij6lxgLkBmZmYtrZ2NCZ/9h0qcgn531dH9xl0F7D1UVZOZEt+a/l1SOGPwUfTrnMJxRzmFfqfkNnb3rGmywpkIsoGeXq974Bz5e5sB3KWqCmwSkS3AAGBxGOMypk55RaXV2uBXttjJzS/2LJPcpjXHdk7mtIFdPEf3/buk0KWtFfim+QlnIlgC9BORvsB2YBpwqc8y3wMTgM9EpAtwHLA5jDEZ45F/uJSN7tH9+p1VVTu7DlYV+IlxMfTrXNkOP9nTNLNbu3gr8E2LEbZEoKplInId8C5O89F5qrpGRK525z8K3AH8W0RW41Ql3aKqe8IVk4lOh4rL2Li7oNqNVxt35ZOTd9izTHxsK47tnMyYYzq6hb1zlN89NSHq+6o3LV9Y7yNQ1beBt32mPer1PAeYFM4YTPQoKilnk1vgO33pOM+z91d1mRDXuhXHdEpmVN/2nqP7/l2S6ZGWaJ2kmahldxabZudwaTnf5hZ4Nc10jvK37S/0dJoWGyMc0ymZ4b3SmJrZ03OU36t9Yp0DhRsTjSwRmIgJNABKcVk5m3MPVd145d5p+93eQ1SOK966ldC3YxJDurfjgozuniP83h2SbIQqY4JkicBEhL8BUGa9tJKFq3fQqpWwYVc+W/cWUu6W+DGthN4dEjmuS2VbfKcOv0+HJOsV05gjZInARMQ9766vMbJVabny7tpd9O2YRL/OyZwxuKunaebRnZJo09qGKTQmHCwRmIjI8dPnPThNxz7+1fhGjcWYaGeJwDSq8grlsc8217jFvFK31IRGjccYY4nANKLv9xbyyxezWLJ1P0O6t2Xj7oJq4+PaACjGRIYlAhN2qsoLS7Zxx5traSXCfRcP5YKM7ryWlWMDoBjTBFgiMGG1O/8wt768mg/X7ebEoztw75ShdHerf2wAFGOaBksEJmwWrt7Bb19dTWFJOX/84fFMP6mPdddgTBNkicCEXF5RKbe9voZXVmxnSPd2PDB1KMd2Tol0WMaYWlgiMCH13017mPXiSnblF3PDhH5cf+qxdoevMU2cJQITEodLy/nrO+t44r9bObpjEi/PPIlhPVMjHZYxJgiWCMwRW7ntADfPz+Lb3ENMP6kPt0weQEKc3QVsTHNhicA0WGl5Bf/4eBN//2gTnZLb8PRPRzG2X6dIh2WMqSdLBKZBNu0u4Jfzs1iZncd5w7px2zmDaZcYG+mwjDENYInA1EtFhfLUF1v5y8J1JMTF8I9LMzgrvWukwzLGHAFLBCZoOW5X0f/dtJdTjuvEXy9Mp3Pb+EiHZYw5QpYITECqyoKs7fzxtTWUVyh/Pn8Il4zqaYO3G9NCWCIwddp3qITfL1jN26t3MqJ3GvdPGUrvDkmRDssYE0KWCEytPlq3i1teXs2BwhJumTyAq8YdbQO8G9MCWSIwNRwqLuNPb63lucXbGHBUCk/OGMXx3dpGOixjTJhYIjDVLNm6j1/OX8m2/YX8/OSjuXlifxsi0pgWzhKBAaC4rJwH3t/Ivz79lh5pCbxw1YmM6ts+0mEZYxqBJQLDNzsOctMLWazbmc8lo3ryu7OOJ7mN/TSMiRb23x7FyiuUuZ9u5v7319MuIY7/+3EmEwZ2iXRYxphGZokgSn2/t5Cb52ex9Lv9TB50FHeeP5gOyW0iHZYxJgIsEUQZVeV5d/zgGBHunzKU84d3t5vDjIlilgiiyO78w/zm5dV8tG43Jx3TgXsurho/2BgTvSwRRIm3V+/gd+74wbPPPp4fn2jjBxtjHGFNBCIyGfgbEAM8rqp3+cyfBVzmFctAoJOq7gtnXNEkr6iUOa+v4VUbP9gYU4uwJQIRiQH+AUwEsoElIvK6qq6tXEZV7wHucZc/G7jJkkDofL5xD7NeWsnu/GJunNCP62z8YGOMH0GVCiLypIiker1OE5F5Ad42CtikqptVtQR4Hji3juUvAZ4LJh5Tt6KScua8voYf/d9XJMTF8MrMk7hpYn9LAsYYv4I9I0hX1QOVL1R1v4gMD/Ce7sA2r9fZwGh/C4pIIjAZuK62lYnIVcBVAL169Qou6ii0ctsBbpqfxWYbP9gYE6RgE0ErEUlT1f0AItI+iPf6uxKptSx7NvDfuqqFVHUuMBcgMzOztvVErdLyCh7+aBMPf7yJzilt+M9PR/ODfh0jHZYxphkINhHcB/xPRF7CKcynAHcGeE820NPrdQ8gp5Zlp2HVQg22aXcBN8/PYlV2HucP786ccwbRLsHGDzbGBCeoRKCqT4nIUuBUnCP9C7wv+tZiCdBPRPoC23EK+0t9FxKRdsDJwI/qE7hxxg/+9/+28td31pEYF8Mjl2Vw5hAbP9gYUz9BJQIROQFYo6oPu69TRGS0qn5V23tUtUxErgPexWk+Ok9V14jI1e78R91FzwfeU9VDR7Ih0cbGDzbGhIqoBq5uF5EVQIa6C4tIK2CpqmaEOT6/MjMzdenSpZH46IhTVV5dsZ3ZrzvjB//hh8czbaSNH2yMCUxElqlqpu/0YK8RiHplDFWtEBG7K7mR7TtUwu9eXc3Cr3eS2TuN+2z8YGNMCARbmG8WkRuAf7qvrwE2hyck48+H3zjjB+cV2fjBxpjQCjYRXA08BPwep9XQh8DPwhWUqVJQXMaf3lzL80uc8YOf/ukoBna18YONMaETbKuh3TitfgAQkQTgh8CLYYrL4IwffPP8LLL3F3H1ycdw08R+Nn6wMSbkgq7nd/sOmoTTFcQk4HMsEYRFcVk597+/gbmfbqZnWiLzf34iI/vY+MHGmPAImAhEZBxO+/+zgMXAGOBoVS0Mc2xRaW3OQW6eb+MHG2MaT50ljIhkA9/jXCSepar5IrLFkkDolVco//r0Wx54fwPtEuKYNz2TUwfY+MHGmPALdKj5MnAeMBUoF5HXqL2/INNA3+09xC/nr2Tpd/s5Y/BR3Hn+ENonxUU6LGNMlKizX2JVvRHoA9wPnAJsADqJyBQRSQ5/eC2bqvLsV99zxt8+Y/2ufB6YOpRHLsuwJGCMaVQBK5/dG8k+Aj4SkVic7qIvAR4BrHvLBtp98DC3vLyKj9fnMubYDtxz0VC62fjBxpgIqNdVSFUtBd4A3nCbkJoGsPGDjTFNSYObo6hqUSgDiQZ5RaXMfu1rFmTlkN6jHfdPGcaxna2GzRgTWdYusZF4jx/8i9P6ce0pNn6wMaZpsEQQZkUl5fz1nXX8+39bOaZTEq9ecxLpPVIjHZYxxngEuo/gDepoLqqq54Q8ohbEe/zgGWOc8YPjY62LCGNM0xLojOBe9+8FwFHAf9zXlwBbwxRTs+c7fvAzV45mzLHWwMoY0zTVmQhU9RMAEblDVcd5zXpDRD4Na2TN1Kbd+dz0wkpWb8/jguHdmW3jBxtjmrhgrxF0EpGjVXUzgDsOcafwhdX8+I4f/M/LMjjDxg82xjQDwSaCm4BFIlI5GE0f4OdhiagZ2n6giFkvruR/3+5lwoDO/OXCIXROsfGDjTHNQ7DjEbwjIv2AAe6kdapaHL6wmgfP+MGvraFClbsuGMJUGz/YGNPMBGo1dKqqfiQiF/jMOkZEUNVXwhhbk7a3oJjfvfo176zZycg+adx38TB6dUiMdFjGGFNvgc4ITsbpZ+hsP/MUiMpEUDl+8MGiUn5zxgB+NtbGDzaRU1paSnZ2NocPH450KKaJiI+Pp0ePHsTGBtdQJVCrodnu3xkhiK3Zs/GDTVOUnZ1NSkoKffr0sWpJg6qyd+9esrOz6du3b1DvCVQ1dHOAD7y/HvE1a4u37OOXL2axfX8RM8cfwy9Os/GDTdNw+PBhSwLGQ0To0KEDubm5Qb8nUNVQypGF1PwVl5Vz/3sbmPtZ1fjBmTZ+sGliLAkYb/X9PQSqGrrtiKJp5tbmHOSmF7JYvyufS0f34ndnDiTJxg82ppoDBw7w7LPPcs0119T7vWeeeSbPPvssqamptS7zxz/+kXHjxnHaaacdQZSmLkGVaiISD/wUGAR4Gsir6k/CFFdEeY8fnJoYxxPTR3LKgM6RDsuYkFiwYjv3vLuenANFdEtNYNbpx3He8O4NXt+BAwd45JFH/CaC8vJyYmJqr0J9++23A67/9ttvb3BskVJWVkbr1s3noDHYfpCfxulr6HTgE6AHkB+uoCLpu72HmPKvL7j7nfVMPL4L7/5inCUB02IsWLGdW19ZzfYDRSjOzZC3vrKaBSu2N3idv/nNb/j2228ZNmwYs2bNYtGiRZxyyilceumlDBkyBIDzzjuPESNGMGjQIObOnet5b58+fdizZw9bt25l4MCB/OxnP2PQoEFMmjSJoiJnyJPp06fz0ksveZafPXs2GRkZDBkyhHXr1gGQm5vLxIkTycjI4Oc//zm9e/dmz549NWKdOXMmmZmZDBo0iNmzZ3umL1myhJNOOomhQ4cyatQo8vPzKS8v51e/+hVDhgwhPT2dv//979ViBli6dCnjx48HYM6cOVx11VVMmjSJK664gq1btzJ27FgyMjLIyMjgf//7n+fz7r77boYMGcLQoUM9319GRoZn/saNGxkxYkSD90l9BZuyjlXVi0XkXFV9UkSeBd4NZ2CNTVV5bvE2/vTWWmJaCQ9OHca5w7pZ3atpVm57Yw1rcw7WOn/F9wcoKa+oNq2otJxfv7SK5xZ/7/c9x3dry+yzB9W6zrvuuouvv/6arKwsABYtWsTixYv5+uuvPa1W5s2bR/v27SkqKmLkyJFceOGFdOjQodp6Nm7cyHPPPcdjjz3GlClTePnll/nRj35U4/M6duzI8uXLeeSRR7j33nt5/PHHue222zj11FO59dZbeeedd6olG2933nkn7du3p7y8nAkTJrBq1SoGDBjA1KlTeeGFFxg5ciQHDx4kISGBuXPnsmXLFlasWEHr1q3Zt29frd9BpWXLlvH555+TkJBAYWEh77//PvHx8WzcuJFLLrmEpUuXsnDhQhYsWMBXX31FYmIi+/bto3379rRr146srCyGDRvGE088wfTp0wN+XqgEmwhK3b8HRGQwsBOnm4k6ichk4G9ADPC4qt7lZ5nxwINALLBHVU8OMqaQ2X3wML9+eRWL1ufyg2M7cvdF6TZ+sGmRfJNAoOkNNWrUqGpNFx966CFeffVVALZt28bGjRtrJIK+ffsybNgwAEaMGMHWrVv9rvuCCy7wLPPKK86tTJ9//rln/ZMnTyYtLc3ve+fPn8/cuXMpKytjx44drF27FhGha9eujBw5EoC2bZ0m4R988AFXX321p4qnffvAjUTOOeccEhKcsqO0tJTrrruOrKwsYmJi2LBhg2e9M2bMIDExsdp6r7zySp544gnuv/9+XnjhBRYvXhzw80Il2EQwV0TSgD8ArwPJ7vNaiUgM8A9gIpANLBGR11V1rdcyqcAjwGRV/V5EGr0O5q1VO/jdgtUcLi3ntnMGcfkJvW38YNNs1XXkDjDmro/YfqDmKLPdUxN44ecnhiyOpKQkz/NFixbxwQcf8MUXX5CYmMj48eP93vzWpk0bz/OYmBhP1VBty8XExFBWVgY4Z/SBbNmyhXvvvZclS5aQlpbG9OnTOXz4MKrq98y/tumtW7emosJJnL7b4b3dDzzwAF26dGHlypVUVFQQHx9f53ovvPBCz5nNiBEjaiTKcKrzGoGIrBWR3wEfq+p+Vf1EVY9W1c6q+q8A6x4FbFLVzapaAjwPnOuzzKXAK6r6PYCq7m7gdtRbXmEpv3h+Bdc+u5ze7RN564ax/PgkG0TetGyzTj+OBJ/BkRJiY5h1+nENXmdKSgr5+bVfMszLyyMtLY3ExETWrVvHl19+2eDPqs0PfvAD5s+fD8B7773H/v37ayxz8OBBkpKSaNeuHbt27WLhwoUADBgwgJycHJYsWQJAfn4+ZWVlTJo0iUcffdSTbCqrhvr06cOyZcsAePnll2uNKS8vj65du9KqVSuefvppysvLAZg0aRLz5s2jsLCw2nrj4+M5/fTTmTlzJjNmNO49vIEuFl+Cc/T/noh8JSK/EJFg+1buDmzzep3tTvPWH0gTkUUiskxErqhtZSJylYgsFZGl9blRotKCFdsZc9dH9P3NW4y4433G3v0Rb6zawU2n9eflmSdxTCcbRN60fOcN785fLhhC99QEBOdM4C8XDDmiVkMdOnRgzJgxDB48mFmzZtWYP3nyZMrKykhPT+cPf/gDJ5xwwhFsgX+zZ8/mvffeIyMjg4ULF9K1a1dSUqrfBjV06FCGDx/OoEGD+MlPfsKYMWMAiIuL44UXXuD6669n6NChTJw4kcOHD3PllVfSq1cv0tPTGTp0KM8++6zns2688UbGjh1bZ4uoa665hieffJITTjiBDRs2eM4WJk+ezDnnnENmZibDhg3j3nvv9bznsssuQ0SYNGlSqL+iOkkwp1QAInICMBW4ENgEPKeqj9Wx/MXA6ap6pfv6cmCUql7vtczDQCYwAUgAvgDOUtUNdcWSmZmpS5cuDSpuqGopUVRaXhUfcNPEftwwoX/Q6zGmKfrmm28YOHBgpMOIqOLiYmJiYmjdujVffPEFM2fO9Fy8bk7uvfde8vLyuOOOO454Xf5+FyKyTFUzfZcNuqGrqn4JfCkirwEPAA8DtSYCnDOAnl6vewA5fpbZo6qHgEPuqGdDgToTQX3d8+76akkAnB7zXliSbYnAmBbg+++/Z8qUKVRUVBAXF8djj9VVNDVN559/Pt9++y0fffRRo392sDeUjcSpJroQZ6ziucCLAd62BOjnjma2HZiGc03A22vAwyLSGogDRuMkmZDK8XNxrK7pxpjmpV+/fqxYsSLSYRyRylZPkRCo07k/41QH7ce52DtGVbODWbGqlonIdTj3G8QA81R1jYhc7c5/VFW/EZF3gFVABU4T068bvjn+dUtN8NtSwpqIGmNM4DOCYuCMQHX2tVHVt4G3faY96vP6HuCehqw/WLNOP67GNYIjbSlhjDEtRVR0OlfZIiKU/asYY0xLEahqaAvOdVVx/9ZYxJ3+oKo+FPrwQue84d2t4DfGGD/qvI9AVfu6N5BV/vV9VE5v0knAGNO0JCc79+3k5ORw0UUX+V1m/PjxBGom/uCDD3puzAKnW+sDBw6ELM5oEVTvoyLS1+2KuvJ1vIj0CVtUxpjwWTUfHhgMc1Kdv6vmRyyUbt26eXoWbQjfRPD222/XObZBU6Oqnu4qIinYbqhfxGnVU6mCwM1HjTFNzar58MYNkLcNUOfvGzccUTK45ZZbeOSRRzyv58yZw3333UdBQQETJkzwdBn92muv1Xjv1q1bGTx4MABFRUVMmzaN9PR0pk6dWq2vIX/dRz/00EPk5ORwyimncMoppwDVu4i+//77GTx4MIMHD+bBBx/0fF5t3V17e+ONNxg9ejTDhw/ntNNOY9euXQAUFBQwY8YMT9fUlV1MvPPOO2RkZDB06FAmTJjg+R687xoePHgwW7du9cRwzTXXkJGRwbZt2+rVPfbYsWOr3Sw3ZswYVq1aFeTeqoWqBnwAWX6mrQzmveF4jBgxQo0xjrVr11a9ePsW1Xln1v64vZPq7LY1H7d3qv09b99S5+cvX75cx40b53k9cOBA/e6777S0tFTz8vJUVTU3N1ePOeYYraioUFXVpKQkVVXdsmWLDho0SFVV77vvPp0xY4aqqq5cuVJjYmJ0yZIlqqq6d+9eVVUtKyvTk08+WVeuXKmqqr1799bc3FzPZ1e+Xrp0qQ4ePFgLCgo0Pz9fjz/+eF2+fLlu2bJFY2JidMWKFaqqevHFF+vTTz9dY5v27dvnifWxxx7Tm2++WVVVf/3rX+uNN95Ybbndu3drjx49dPPmzdVinT17tt5zzz2eZQcNGqRbtmzRLVu2qIjoF1984Znnb/uKi4u1b9++unjxYlVVzcvL09LSUv33v//tiWH9+vVaW3lY7XfhApaqnzI12DOCXBE5p/KFiJwL1Bz1wRjTtJUX1296EIYPH87u3bvJyclh5cqVpKWl0atXL1SV3/72t6Snp3Paaaexfft2z5G1P59++qln/IH09HTS09M98+bPn09GRgbDhw9nzZo1rF27trbVAE631Oeffz5JSUkkJydzwQUX8NlnnwHBdXednZ3N6aefzpAhQ7jnnntYs2YN4HQhfe2113qWS0tL48svv2TcuHGebreD6a66d+/e1fpc8rd969evr9E9duvWrbn44ot58803KS0tZd68eSEZtyDYLiauBp5x+wYCp2uIWjuIM8ZEyBk1hvyo7oHBbrWQj3Y9YcZbDf7Yiy66iJdeeomdO3cybdo0AJ555hlyc3NZtmwZsbGx9OnTx2/30978dc9cW/fRddE6+lALprvr66+/nptvvplzzjmHRYsWMWfOHM96fWP0Nw2qd1cN1bus9u6uur7dYycmJjJx4kRee+015s+fH/CCejCCOiNQ1W9V9QTgeGCQqp6kqpuO+NONMY1rwh8h1ueO+tgEZ/oRmDZtGs8//zwvvfSSpxVQXl4enTt3JjY2lo8//pjvvvuuznWMGzeOZ555BoCvv/7aU+9dW/fRUHsX2OPGjWPBggUUFhZy6NAhXn31VcaOHRv09uTl5dG9u9Pc/Mknn/RMnzRpEg8//LDn9f79+znxxBP55JNP2LJlC1C9u+rly5cDsHz5cs98X/XtHhucQWxuuOEGRo4cGdQZSCDBthr6s4ikqmqBquaLSJqI/OmIP90Y07jSp8DZDzlnAIjz9+yHnOlHYNCgQeTn59O9e3e6dnV6qr/ssstYunQpmZmZPPPMMwwYMKDOdcycOZOCggLS09O5++67GTVqFFB799EAV111FWeccYbnYnGljIwMpk+fzqhRoxg9ejRXXnklw4cPD3p75syZw8UXX8zYsWPp2LGjZ/rvf/979u/fz+DBgxk6dCgff/wxnTp1Yu7cuVxwwQUMHTqUqVOnAs5AM/v27WPYsGH885//pH9//x1c1rd7bHCqtNq2bRuycQuC6oZaRFao6nCfactVNaO294RTfbuhNqYls26oo09OTg7jx49n3bp1tGrl/3i+Pt1QB3uxOEZEPBVrIpIAtKljeWOMMWHw1FNPMXr0aO68885ak0B9BXux+D/AhyLyBE6XEj8BngpJBMYYY4J2xRVXcMUVoW2rE1QiUNW7RWQVcBpO/0J3qOq7IY3EGGNMRNRnhLJ3gHdEJAk4X0TeUtWzwheaMSZYtTU1NNEpmGu/3oJtNRQnIueJyHxgB84Yw48GeJsxphHEx8ezd+/eev/zm5ZJVdm7dy/x8fGBF3YF6oZ6Is4QlacDHwNP4wxAH5o2S8aYI9ajRw+ys7PJzc2NdCimiYiPj6dHjx5BLx+oauhd4DPgB6q6BUBE/tbw8IwxoRYbG+vp3sCYhgiUCEbgDDr/gYhsxhm3OCbsURljjGk0gQamWaGqt6jqMcAcYDgQJyILReSqxgjQGGNMeAV9N4Kq/ldVrwO6Aw8CJ4YrKGOMMY0n6OajlVS1Aufagd1HYIwxLUBo7k82xhjTbFkiMMaYKBd01ZCIxABdvN+jqt+HIyhjjDGNJ6hEICLXA7OBXVQNYq9Aeq1vMsYY0ywEe0ZwI3Ccqu4NZzDGGGMaX7DXCLYBeeEMxBhjTGQEe0awGVgkIm8BxZUTVfX+sERljDGm0QSbCL53H3HuwxhjTAsR7MA0tzVk5SIyGfgbTv9Ej6vqXT7zxwOvAVvcSa+o6u0N+SxjjDENE6gb6gdV9Rci8gZOK6FqVPWcOt4bA/wDmAhkA0tE5HVVXeuz6Geq+sP6h26MMSYUAp0RPO3+vbcB6x4FbFLVzQAi8jxwLuCbCIwxxkRQnYlAVZe5fz9pwLq747Q2qpQNjPaz3IkishLIAX6lqmv8rczt7fQqgF69ejUgHGOMMf4EO1RlPxF5SUTWisjmykegt/mZ5lu9tBzorapDgb8DC2pbmarOVdVMVc3s1KlTMGEbY4wJQrD3ETwB/BMoA04BnqKq2qg22UBPr9c9cI76PVT1oKoWuM/fBmJFpGOQMRljjAmBYBNBgqp+CIiqfqeqc4BTA7xnCdBPRPqKSBzOSGevey8gIkeJiLjPR7nx2N3LxhjTiIK9j+CwiLQCNorIdcB2oHNdb1DVMnfZd3Gaj85T1TUicrU7/1HgImCmiJQBRcA0Va3ROskYY0z4SDDlroiMBL4BUoE7gLbAPar6ZVijq0VmZqYuXbo0Eh9tjDHNlogsU9VM3+kBzwjc+wGmqOosoACYEYb4jDHGREid1whEpLWqlgMjKuvyjTHGtCyBzggWAxnACuA1EXkROFQ5U1VfCWNsxhhjGkGwF4vb47TmORXnXgBx/1oiMMaYZi5QIugsIjcDX1OVACpZ6x5jjGkBAiWCGCCZ4O4SNsYY0wwFSgQ7rFtoY4xp2QLdWWwthYwxpoULlAgmNEoUxhhjIqbORKCq+xorEGOMMZERbKdzxhhjWihLBMYYE+UsERhjTJSzRGCMMVHOEoExxkQ5SwTGGBPlLBEYY0yUs0RgjDFRzhKBMcZEOUsExhgT5SwRGGNMlLNEYIwxUc4SgTHGRDlLBMYY09Stmg8PDIY5qc7fVfNDuvpgB683xhgTCavmwxs3QGmR8zpvm/MaIH1KSD7CEoExxjQV5aVQUgDFBVByyHm8+9uqJFCptAg+vN0SgTHGRFRFeVVhXVLgPg65hbjX65JDUJxfx7Je08pLgv/8vOyQbYolAmNMy6cKpYVBFMreBfOhmkfnJV7vLS0M/vNbx0NcMsQlOX/bJEObFEg5CuJS3OlJznTv5eKS4bVr4dDumuts1yNkX48lAmNMdavmO9UOedlOYTPhjyGrggiKKpQV1yx4j6gALwA0uM9v1dotrFO8CuQkSOzgFtRuoV2tAPd6HudVmLdJhtgkiDmCovb0O6tfIwCITXD2S4iENRGIyGTgb0AM8Liq3lXLciOBL4GpqvpSOGMyxtShIRcm/dVrH2kBruXBxSutqhe8lYVySlfo4KdQ9i2oK4/Ovae3jjvy7zGUKr/3MCZnUQ0yS9Z3xSIxwAZgIpANLAEuUdW1fpZ7HzgMzAsmEWRmZurSpUtDH7Qx0UTVKaSL9ruPffDylVC4t+ayrROg1+gjr9eOTarjqNpPtUigArx1PIiE7jtp4URkmapm+k4P5xnBKGCTqm52A3geOBdY67Pc9cDLwMgwxmJMy+WvQPc83w+F+2ufV1EW3GeUFUFJoVe9doCjan8Fe2witLJbl5qicCaC7sA2r9fZwGjvBUSkO3A+cCoBEoGIXAVcBdCrV6+QBmpMk1CjQPcpuKsV6D7z6irQ45IhIQ0SUiGhPXQ+3nmd2N6dXvloDy9Oh4KdNdfRridc+X64ttxEWDgTgb/zNd96qAeBW1S1XAKc3qnqXGAuOFVDoQjQmLBo7AK9RqHu/TwVWrcJPvZJd4T9wqRpesKZCLKBnl6vewA5PstkAs+7SaAjcKaIlKnqgjDGZUxwVJ068MJ9tVStHKh9XtAFelodBbp3oZ5avwK9oRrhwqRpesKZCJYA/USkL7AdmAZc6r2AqvatfC4i/wbetCQQRRqrmaLfAt274D5Q+7y6CvTYJLfgTm16BfqRSJ9iBX+UCVsiUNUyEbkOeBen+eg8VV0jIle78x8N12ebZqAhzRQbrUAfUL16xW+1S2rTL9CNCVLYmo+GkzUfbQEeGOwU/r7atIOMy926dD/VLvUp0H3ry/0epadagW6iRiSajxpTXcFuyMmCnBX+kwBAcR4sfcItuNP8H6H7PUpPtQLdmAayRGDCoyAXdmRVFfw7suDgdnemOLfx+zu6b9cDblrTeHEaYywRmBA4tBd2rHAK/Jws53HQq2fEDv2g90nQbTh0HQZd02H9wlqaKc5u5OCNMZYITP0U7qs6ws9ZATkrIe/7qvntj3G6Iuh2dVWhH9+u5nqsmaIxTYYlAlO7ov3O0b2n0F8BB7wK/bS+0CMTRl3pHO0fle7U1QfLmika0yRYIjCOogOwY2X1o/39W6vmp/WBbhmQ+VPoNgy6DnUu1Bpjmj1LBNHocJ5b6GdVFfz7NlfNT+3lHOFn/Nit1x/qtNIxxrRIlghausMHYecqrwu5K2Dft1Xz2/V0jvCHXeYU+t2GW6FvTJSxRNCSFOfDjlVedfpZsHcTnr7+2vZwC/1LoOtw53lSx4iFa4xpGiwRNFfFBbBzdfVCf88GPIV+Sjfn6D59SlWzzeROkYvXGNNkWSJoDkoKnULf+0Lung2gFc785KOcwn7wBVWFfkqXSEZsjGlGLBE0NSWFsOvr6hdyc9dVFfpJnZ3C/vjz3NY7w6Bt14iFa4xp/iwRRFJpEexaU/1Cbu66qoG7kzo5hf6AH7oXcoc5g3LbGK3GmBCyRNBYSg/D7jVVN2blrITda6sK/cQObqF/pnOU3204tO1mhb4xJuwsEYRDWbFzpO99IXf32qpO1hLaOwV9/0lVdfrtelihb4yJCEsER6qsxCnkvS/k7loLFaXO/PhUp7A/6fqqQj+1lxX6xpgmwxJBfZSXuoV+VlXBv2sNlJc48+PbOQX9idc69fndhkNqbyv0jTFNmiWC2pSXOhduvS/k7loD5cXO/DbtnJ41R19ddSE3ra8V+saYZid6EkFdA6WXl8Ge9T6F/tdQdtiZH5fiFPSjflbVDUNaX2jVKlJbY4wxIRMdicDfQOmvXQtZz0LJIedmrTJ3Xlyy08nayCurWu+0P9oKfWNMixUdieDD26uPhAVOvf7mRdDrRMicUXUht8OxVugbY6JKdCSCvOza5/1kYePFYYwxTVB0HPq261G/6cYYE0WiIxFM+KMzMLq32ARnujHGRLnoSATpU+Dsh5xBWBDn79kP2Xi5xhhDtFwjABso3RhjahEdZwTGGGNqZYnAGGOinCUCY4yJcpYIjDEmylkiMMaYKCeqGukY6k1EcoHvGvj2jsCeEIYTSS1lW1rKdoBtS1PVUrblSLejt6p28p3YLBPBkRCRpaqaGek4QqGlbEtL2Q6wbWmqWsq2hGs7rGrIGGOinCUCY4yJctGYCOZGOoAQainb0lK2A2xbmqqWsi1h2Y6ou0ZgjDGmumg8IzDGGOPFEoExxkS5FpsIRGSyiKwXkU0i8hs/80VEHnLnrxKRjEjEGUgQ2zFeRPJEJMt9NMlBFkRknojsFpGva5nfLPYHBLUtzWKfAIhITxH5WES+EZE1InKjn2Wa/L4JcjuaxX4RkXgRWSwiK91tuc3PMqHdJ6ra4h5ADPAtcDQQB6wEjvdZ5kxgISDACcBXkY67gdsxHngz0rEGsS3jgAzg61rmN/n9UY9taRb7xI21K5DhPk8BNjTT/5VgtqNZ7Bf3e052n8cCXwEnhHOftNQzglHAJlXdrKolwPPAuT7LnAs8pY4vgVQR6drYgQYQzHY0C6r6KbCvjkWaw/4AgtqWZkNVd6jqcvd5PvAN0N1nsSa/b4LcjmbB/Z4L3Jex7sO3VU9I90lLTQTdgW1er7Op+aMIZplICzbGE93TyIUiMqhxQgu55rA/6qPZ7RMR6QMMxzkC9das9k0d2wHNZL+ISIyIZAG7gfdVNaz7pKWOUCZ+pvlm1GCWibRgYlyO039IgYicCSwA+oU7sDBoDvsjWM1un4hIMvAy8AtVPeg7289bmuS+CbAdzWa/qGo5MExEUoFXRWSwqnpfkwrpPmmpZwTZQE+v1z2AnAYsE2kBY1TVg5Wnkar6NhArIh0bL8SQaQ77IyjNbZ+ISCxO4fmMqr7iZ5FmsW8CbUdz2y8AqnoAWARM9pkV0n3SUhPBEqCfiPQVkThgGvC6zzKvA1e4V99PAPJUdUdjBxpAwO0QkaNERNzno3D26d5Gj/TINYf9EZTmtE/cOP8P+EZV769lsSa/b4LZjuayX0Skk3smgIgkAKcB63wWC+k+aZFVQ6paJiLXAe/itLyZp6prRORqd/6jwNs4V943AYXAjEjFW5sgt+MiYKaIlAFFwDR1mxU0JSLyHE6rjY4ikg3MxrkI1mz2R6UgtqVZ7BPXGOByYLVbJw3wW6AXNKt9E8x2NJf90hV4UkRicJLVfFV9M5zll3UxYYwxUa6lVg0ZY4wJkiUCY4yJcpYIjDEmylkiMMaYKGeJwBhjopwlAmP8EJFyr14qs8RPz69HsO4+UkvPpcZEQou8j8CYEChS1WGRDsKYxmBnBMbUg4hsFZG/uv3FLxaRY93pvUXkQ7dv+A9FpJc7vYuIvOp2dLZSRE5yVxUjIo+5/c2/595BakxEWCIwxr8En6qhqV7zDqrqKOBh4EF32sM43QKnA88AD7nTHwI+UdWhOGMYrHGn9wP+oaqDgAPAhWHdGmPqYHcWG+OHiBSoarKf6VuBU1V1s9vJ2U5V7SAie4CuqlrqTt+hqh1FJBfooarFXuvog9O1cD/39S1ArKr+qRE2zZga7IzAmPrTWp7Xtow/xV7Py7HrdSaCLBEYU39Tvf5+4T7/H07vsACXAZ+7zz8EZoJnsJG2jRWkMcGyoxBj/Evw6sUS4B1VrWxC2kZEvsI5kLrEnXYDME9EZgG5VPUGeSMwV0R+inPkPxNoUl04G2PXCIypB/caQaaq7ol0LMaEilUNGWNMlLMzAmOMiXJ2RmCMMVHOEoExxkQ5SwTGGBPlLBEYY0yUs0RgjDFR7v8BJw3iWIspbasAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(model.history.history['accuracy'], marker='o', label='training accuracy')\n",
    "plt.plot(model.history.history['val_accuracy'], marker='o', label='validation accuracy')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Acc|Valid Acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This added around 40s to each epoch, and does not look much different than the baseline graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding dense layers to the untrained side of the neural network\n",
    "I have no idea why I just noticed this, but the section of the neural network that is meant to be trainable has just one dense layer, the prediction output. Adding a few more dense layers in order to improve training with the given targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42630 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x1a759a359a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data_generator(image_size = [80,80],\n",
    "                            path = 'data/grassnoted split/asl_alphabet_train',\n",
    "                           )\n",
    "train_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18270 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x1a74082ae80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = data_generator(image_size = [80,80], \n",
    "                                 path = 'data/grassnoted split/asl_alphabet_validation',\n",
    "                                )\n",
    "validation_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26100 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x1a74082aa00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = data_generator(image_size = [80,80],\n",
    "                           path = 'data/grassnoted split/asl_alphabet_test',\n",
    "                          )\n",
    "test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing MobileNetV2 for use in transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "experienced_model = MobileNetV2(weights='imagenet', include_top=False, input_shape = (80,80,3))\n",
    "#input shape minimum is 32x32\n",
    "#this warning is all bark and no bite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining an untrained neural network to attach to the end of MobileNetV2 in order to make predictions in our current problem space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the output of this base_model to a variable:\n",
    "base_model_out = experienced_model.output\n",
    "\n",
    "\n",
    "\n",
    "# Add a pooling layer:\n",
    "base_model_out = GlobalAveragePooling2D()(base_model_out)\n",
    "\n",
    "# Add 3 dense layers so that the model can learn aspects of our new dataset \n",
    "# and classify for better results.\n",
    "base_model_out = Dense(243, activation='relu')(base_model_out) \n",
    "base_model_out = Dense(243, activation='relu')(base_model_out)\n",
    "base_model_out = Dense(81, activation='relu')(base_model_out)\n",
    "\n",
    "# using a softmax base_model_out activation function:\n",
    "preds = Dense(29, activation='softmax')(base_model_out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate our final model, where we specify what are the inputs and \n",
    "# the outputs will look like\n",
    "model = Model(inputs = experienced_model.input, \n",
    "              outputs = preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the number of nodes in the topless MobileNetV2 by looking at the index of the pooling layer. These should be locked in order to preserve their weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 Conv1\n",
      "2 bn_Conv1\n",
      "3 Conv1_relu\n",
      "4 expanded_conv_depthwise\n",
      "5 expanded_conv_depthwise_BN\n",
      "6 expanded_conv_depthwise_relu\n",
      "7 expanded_conv_project\n",
      "8 expanded_conv_project_BN\n",
      "9 block_1_expand\n",
      "10 block_1_expand_BN\n",
      "11 block_1_expand_relu\n",
      "12 block_1_pad\n",
      "13 block_1_depthwise\n",
      "14 block_1_depthwise_BN\n",
      "15 block_1_depthwise_relu\n",
      "16 block_1_project\n",
      "17 block_1_project_BN\n",
      "18 block_2_expand\n",
      "19 block_2_expand_BN\n",
      "20 block_2_expand_relu\n",
      "21 block_2_depthwise\n",
      "22 block_2_depthwise_BN\n",
      "23 block_2_depthwise_relu\n",
      "24 block_2_project\n",
      "25 block_2_project_BN\n",
      "26 block_2_add\n",
      "27 block_3_expand\n",
      "28 block_3_expand_BN\n",
      "29 block_3_expand_relu\n",
      "30 block_3_pad\n",
      "31 block_3_depthwise\n",
      "32 block_3_depthwise_BN\n",
      "33 block_3_depthwise_relu\n",
      "34 block_3_project\n",
      "35 block_3_project_BN\n",
      "36 block_4_expand\n",
      "37 block_4_expand_BN\n",
      "38 block_4_expand_relu\n",
      "39 block_4_depthwise\n",
      "40 block_4_depthwise_BN\n",
      "41 block_4_depthwise_relu\n",
      "42 block_4_project\n",
      "43 block_4_project_BN\n",
      "44 block_4_add\n",
      "45 block_5_expand\n",
      "46 block_5_expand_BN\n",
      "47 block_5_expand_relu\n",
      "48 block_5_depthwise\n",
      "49 block_5_depthwise_BN\n",
      "50 block_5_depthwise_relu\n",
      "51 block_5_project\n",
      "52 block_5_project_BN\n",
      "53 block_5_add\n",
      "54 block_6_expand\n",
      "55 block_6_expand_BN\n",
      "56 block_6_expand_relu\n",
      "57 block_6_pad\n",
      "58 block_6_depthwise\n",
      "59 block_6_depthwise_BN\n",
      "60 block_6_depthwise_relu\n",
      "61 block_6_project\n",
      "62 block_6_project_BN\n",
      "63 block_7_expand\n",
      "64 block_7_expand_BN\n",
      "65 block_7_expand_relu\n",
      "66 block_7_depthwise\n",
      "67 block_7_depthwise_BN\n",
      "68 block_7_depthwise_relu\n",
      "69 block_7_project\n",
      "70 block_7_project_BN\n",
      "71 block_7_add\n",
      "72 block_8_expand\n",
      "73 block_8_expand_BN\n",
      "74 block_8_expand_relu\n",
      "75 block_8_depthwise\n",
      "76 block_8_depthwise_BN\n",
      "77 block_8_depthwise_relu\n",
      "78 block_8_project\n",
      "79 block_8_project_BN\n",
      "80 block_8_add\n",
      "81 block_9_expand\n",
      "82 block_9_expand_BN\n",
      "83 block_9_expand_relu\n",
      "84 block_9_depthwise\n",
      "85 block_9_depthwise_BN\n",
      "86 block_9_depthwise_relu\n",
      "87 block_9_project\n",
      "88 block_9_project_BN\n",
      "89 block_9_add\n",
      "90 block_10_expand\n",
      "91 block_10_expand_BN\n",
      "92 block_10_expand_relu\n",
      "93 block_10_depthwise\n",
      "94 block_10_depthwise_BN\n",
      "95 block_10_depthwise_relu\n",
      "96 block_10_project\n",
      "97 block_10_project_BN\n",
      "98 block_11_expand\n",
      "99 block_11_expand_BN\n",
      "100 block_11_expand_relu\n",
      "101 block_11_depthwise\n",
      "102 block_11_depthwise_BN\n",
      "103 block_11_depthwise_relu\n",
      "104 block_11_project\n",
      "105 block_11_project_BN\n",
      "106 block_11_add\n",
      "107 block_12_expand\n",
      "108 block_12_expand_BN\n",
      "109 block_12_expand_relu\n",
      "110 block_12_depthwise\n",
      "111 block_12_depthwise_BN\n",
      "112 block_12_depthwise_relu\n",
      "113 block_12_project\n",
      "114 block_12_project_BN\n",
      "115 block_12_add\n",
      "116 block_13_expand\n",
      "117 block_13_expand_BN\n",
      "118 block_13_expand_relu\n",
      "119 block_13_pad\n",
      "120 block_13_depthwise\n",
      "121 block_13_depthwise_BN\n",
      "122 block_13_depthwise_relu\n",
      "123 block_13_project\n",
      "124 block_13_project_BN\n",
      "125 block_14_expand\n",
      "126 block_14_expand_BN\n",
      "127 block_14_expand_relu\n",
      "128 block_14_depthwise\n",
      "129 block_14_depthwise_BN\n",
      "130 block_14_depthwise_relu\n",
      "131 block_14_project\n",
      "132 block_14_project_BN\n",
      "133 block_14_add\n",
      "134 block_15_expand\n",
      "135 block_15_expand_BN\n",
      "136 block_15_expand_relu\n",
      "137 block_15_depthwise\n",
      "138 block_15_depthwise_BN\n",
      "139 block_15_depthwise_relu\n",
      "140 block_15_project\n",
      "141 block_15_project_BN\n",
      "142 block_15_add\n",
      "143 block_16_expand\n",
      "144 block_16_expand_BN\n",
      "145 block_16_expand_relu\n",
      "146 block_16_depthwise\n",
      "147 block_16_depthwise_BN\n",
      "148 block_16_depthwise_relu\n",
      "149 block_16_project\n",
      "150 block_16_project_BN\n",
      "151 Conv_1\n",
      "152 Conv_1_bn\n",
      "153 out_relu\n",
      "154 global_average_pooling2d\n",
      "155 dense\n",
      "156 dense_1\n",
      "157 dense_2\n",
      "158 dense_3\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that layer 154 is where our added layers begin. We will lock all layers above 154 and make them untrainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_average_pooling2d\n",
      "dense\n",
      "dense_1\n",
      "dense_2\n",
      "dense_3\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:154]:\n",
    "    layer.trainable=False\n",
    "    \n",
    "for layer in model.layers[154:]:\n",
    "    print(layer.name)\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', #loss function\n",
    "                  optimizer = 'Adam',\n",
    "                  metrics = ['accuracy']) #value to maximize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size_train = train_data.n//train_data.batch_size + 1\n",
    "\n",
    "# 'train_data.n' = 60,900 images\n",
    "# 'train_generator.batch_size' = 80 images per batch\n",
    "# 'step_size_train' = 762  (!needs to be int)\n",
    "step_size_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h\\.conda\\envs\\deeplearningcopy\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "533/533 [==============================] - 182s 335ms/step - loss: 1.9353 - accuracy: 0.4259 - val_loss: 2.3210 - val_accuracy: 0.3550\n",
      "Epoch 2/4\n",
      "533/533 [==============================] - 180s 337ms/step - loss: 0.6844 - accuracy: 0.7691 - val_loss: 2.4066 - val_accuracy: 0.3996\n",
      "Epoch 3/4\n",
      "533/533 [==============================] - 180s 338ms/step - loss: 0.5024 - accuracy: 0.8279 - val_loss: 2.4265 - val_accuracy: 0.4195\n",
      "Epoch 4/4\n",
      "533/533 [==============================] - 182s 341ms/step - loss: 0.4268 - accuracy: 0.8519 - val_loss: 2.5719 - val_accuracy: 0.4237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a7632c4f40>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_data, validation_data = validation_data, steps_per_epoch = step_size_train, epochs = 4, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Model Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6QUlEQVR4nO3deXxU9bn48c9DFpIQEggBZBUUFAhrDItSEBcQ9borIlqrXrVC3drqVfu7Vau19apVtG4XvVhtQcUN96VaEK0bO7KDiBDCkgTIAtnz/P44J5PJZJKZhEwmyTzv12temTnrc+ZMvs853/M93yOqijHGmMjVLtwBGGOMCS9LBMYYE+EsERhjTISzRGCMMRHOEoExxkQ4SwTGGBPhLBG0YCLyoYj8oqmnNaEnIpNEJDMEy+0nIioi0e7nOve777SNWNfvROT5I4nXtA6WCJqYiBR6vSpFpMjr8+UNWZaqnqmqLzb1tI0hIv3d7Xk6VOuIFCKyUUSu8TP8FhFZ1pBlNdV+95e4VPVPqnrtkS47wDpVRP4rVOswwbFE0MRUNbHqBewAzvEaNq9qusYepYXRlcABYLqItG/OFYtIVHOurxm8iPN9+vq5Oy5S/ALY7/5tNuKwss+bqtorRC9gO3C6+34SkAncAewB/g50Bt4DsnEK2feA3l7zLwaudd9fBXwJPOJO+yNwZiOn7Q8sAQqAT4GngH8E2JYfgJnAXuBin3HnAauAfHe6qe7wFOAFIMuNY6F3fD7LUGCA+/5vwDPAB8Ah4HTgbGClu46dwL0+8/8M+Ao46I6/ChjtxhvtNd1FwKo6trHOdQD93Bh/gZPgc4D/5zU+3o37ALAeuB3IrGM9vYFy4GivYYOBUiA1yDii/ez3KHef5wDbgF/5THs1sMHd79uAX7rDOwBFQCVQ6L56Avd6/y6Ac4F17ne8GBjs81u/DVgD5AGvAnH1/J4S3Dimu9ud4TP+Oq9Y1wPp7vA+wJs4/zO5wJPucN9Y/X1PDwD/drd1QF3fR32/a+ASYLnPdL/F/W231lfYA2jLL2ongnLgf4D2OAVHF5yCKQHoCLzm/YOiduFe5v6DROEUylmANGLar3EKjFicAjSfehIBMAEowUlcfwXe8Ro3xv3Hn4xzhtkLGOSOe98tEDoDMcDJXvEFSgR5wHh3mXHu9zfM/Twcp4A/352+r/vPfJm7ni7ASHfcemomwbeA39axnfWto58b43PuvhvhfieD3fEPAl/gJL8+wFrqSATu9P8E/tvr85+pTpTBxOEvEdwAbHTXnwIs8pn2bOBYQICTgcNUF7CTfOPFq3AFjsNJypPd7/i/gK1ArNdv/TucBJKCU8DeUM/2/xzYjfP7fBd4wmvcJcAunEQuOIX20e60q4HHcJJXHPAz31jr+Z52AGlAtLsN9X0ffn/XOP+7+6mZBFcCF4W7vDmisircAbTlF7UTQSn1HyWNBA54ffb+J78K2Oo1LsH9oR/VkGlxCs1yIMFr/D+oPxE8T3UhdSJOkunmfv5f4DE/8/TAOcLs7GfcVQROBC8F+G5nV60XuAt4q47p7gDmue9T3H/2HkHuP+91VBUs3mds3wHT3ffbcM+E3M/XU38iuALY5L5v5xZSFzQgDn+J4F94Fb7AFO9p/Sx3IXCL1++zvkTwe2CB17h2OIX1JK/f+hVe4x8Cnq1n+z8FZrvvL8M5wo9xP39cFZfPPCe609XaHoJLBPcF2N/e34ff37U77hngAfd9Gs5ZYPtgflMt9WX1ZM0rW1WLqz6ISIKI/K+I/CQi+TjVNZ3qqRPfU/VGVQ+7bxMbOG1PYL/XMHCqH/wSkXicI7R57rK+xim0ZriT9ME5bfbVx13PgbqWHUCNmERkrIgsEpFsEcnDOfpNDRADOEnuHBFJBKYBX6jqbn8TBlhHlT1e7w9T/f339In5p/o3jzeBHiIyDqcQTsA5gwo2Dn/qjUFEzhSRb0Rkv4gcBM4KcrlVy/YsT1Ur3XX18pqmru+mBhHpA5yC+5sC3sY5uj/b/Vzfb+onVS0PMmZfvr+p+r6P+n5TLwIzRERwzmwWqGpJI2NqESwRNC/1+fxb4HhgrKomARPd4RLCGHYDKSKS4DWsTz3TXwAkAU+LyB4R2YPzz191sXMnzum1r53uejr5GXcIp+ADQESO8jON73c1H3gH6KOqycCzVH9PdcWAqu7CqQq7AOef9u/+pgtiHYHspub32Le+id1E/DrO9/hz4BVVLT3COOqMwb3A/wZOlWB3Ve2Ecw2marm+37evLJzqmarlibuuXUHE5evnOGXPu+7vaRtOIgjmN9W3joYWNX5TOGe/vjzbGMT3Ud9v6hucs/sJOAdE9f2mWgVLBOHVEefC1UERSQHuCfUKVfUnYBlwr4jEisiJwDn1zPILYC5OnfVI9zUeGCkiw4D/A64WkdNEpJ2I9BKRQe5R94c4CaSziMSISFWiWw2kichIEYnDOa0PpCPOGUaxiIyh+owEnCPL00VkmohEi0gXERnpNf4lnDrtYTjXCBqzjkAWAHe529obuCmIeV4ELsW5TuTdWqixcSwAbhaR3iLSGbjTa1wsTv12NlAuImfiVB1V2Qt0EZHkepZ9trufY3AOYkpwLtA31JXAH6j+PY3E+Q7OFpEuOFWRt4nICW4LnwEicjROVdxu4EER6SAicSIy3l3mKmCiiPR1t+GuADEE+j78/q69xr8EPAmUq+qXjfgOWhRLBOE1G+fCYw7wDfBRM633cpz61lzgjzgXdGud2opIL+A0nLrcPV6v5W6sv1DV73BaXzyGc3Htc6qPHH+Ocz1hI7APuBVAVTcD9+HUE2/BaeEUyCzgPhEpAO7GKZhwl7cD57T+tzgX8lbhXMyt8pYb01uqeqgx6wjCH3CqTn4EPiG4o8QlON/ZLlVd2gRxPIdTv74aWIFT/QSAqhYAN7vLOoCTXN7xGr8ReBnYJiIHRaSn94JVdRPOdY2/4vxez8FpGl1KA7hVYf2Ap3x+U+/gXHy+TFVfw2nhMx+nEcBCIEVVK9z1DsCpnszESaSo6j9xfsdrgOU4LfDqFMT3Ud/vGpz9O5Q2cDYA1a1ITAQTkVeBjaoa8jOScBGRH3CaB34a7lhM6+deO9uH08poS7jjOVJ2RhCBRGS0iBzrnvJOxWkvvTDMYYWMiFyEUz/8r3DHYtqMmcDStpAEwGlPayLPUTjVBl1wTq9nqurK8IYUGiKyGBgC/Nxt6WLMERGR7TgXlc8PbyRNx6qGjDEmwlnVkDHGRLhWWTWUmpqq/fr1C3cYxhjTqixfvjxHVbv6Dm+ViaBfv34sW9ag3nqNMSbiiYjfO96tasgYYyKcJQJjjIlwlgiMMSbCWSIwxpgIZ4nAGGMiXKtsNWSMMZFk4cpdPPzxJrIOFtGzUzy3n3E854/qFXjGIFkiMMaYFmzhyl3c9eb3FJVVALDrYBF3vfk9QJMlA6saMsaYFqaiUskuKGHD7nzuf2+9JwlUKSqr4OGPNzXZ+uyMwBhjmkFJeQW5haXkFJaQW1hKdmEJOYUl5BSUknuo5vv9h0qpDNANXNbBoiaLzRKBMcY00qGScqcALywhxy3kcwrcwv5Q9fucwhLyi/0/ajkhNoouibGkJranb5cE0o/uTKr7OTWxPfe8s5acwtrP/+nZKb7JtsMSgTHGuFSVvKIycgpLyK46Ui/wKuQLqwv23MLSWlU2VZLjY0hNjKVLYnsG90jyvHcK91hSO7YntUN7UjvGkhBbfzFcVlFZ4xoBQHxMFLefcXyTbbclAmNMm1ZeUcn+w6U1js6rqmiyvd5XDS/3UyfTTiClQ3vPkXq/LglOod6xPV06OAV718T2dEmMpUuH9sRGN93l16oLwtZqyBhjvBSXVZB7qNQ9Wvepmil0hjv17qUcOFyKv8euxEa18xydd+vYniE9kpwj9cT2NapmUhNj6ZQQS1Q7af4NdZ0/qleTFvy+LBEYY8JOVSksKSensJRct2DP9npfXe/uFPIFJf7r2zvERnkK8/6pHcjol0JqYnu6+qma6dg+GpHwFe4tiSUCY0wNTXXzUmWlctCtb/c+Us/xqY6pOpIvKff/JNHOCTFuIR5LWs+kWkfsXbzex8dGHenmRyRLBMYYj0A3L5VVVLL/UCnZBSW1qmaqm0Q6R/K5h0qp8FPfHtVO6NIh1lO4H9s1sbqu3avevWvH9qR0iCUmym53CrVW+czijIwMtQfTGNP0TvzzZ+zOK641PLqdkBgXzcHDZX7nax/drnbdekfnwqlTVRPrXkxtT6f4GNqFsb49konIclXN8B1uZwTGRCBVJSuvmHW78liXlc+6rHzWZ+X5TQIA5ZXKfwzv4VbFOHXu3lUziVbf3qpZIjCmjauoVLZlF7oFvlPwr9+d7zm6bydwTNdEMvqlsHjTPr83PvXqFM8fzx/W3KGbZmKJwJg2pLisgk17CmoU+hv35FNc5lyIjY1ux6CjOnLm0KMY0jOZtJ5JDDqqo+emJt9rBND0Ny+ZlscSgTGtVN7hMtbtzmO9p2onn63ZhZ4LtB3johnSI4kZY44mrWcSab2SOLZrYr0XX5vj5iXT8lgiMKaFU1X25pd4jvCr/mYeqO50rHtSe9J6JjN5SHen0O+ZTJ+U+EbV24f65iXT8lgiMKYFqaxUfsw95DnKX5flHPHnHqrudKx/agdG9OnEjLF9SeuZzJAeSXTt2D6MUZvWzhKBMWFSUl7Blr2FXkf6+WzYnc/hUqd+PiZKOK57R04d1M2t2klmcI8kEtvbv61pWvaLMqYZFBSXsd5trVNV6G/ZW+Dp4KxDbBRDeiYxLaMPQ3omkdYziYHdOjZp52XG1MUSgTFNbF9BsefibdXR/k+5hz3jUxNjGdIzmUnHd/XU5x+dkmA3WZmwCWkiEJGpwONAFPC8qj7oMz4Z+AfQ143lEVV9IZQxGdNUKiuVnQcO17iAuy4rn+yCEs80fVMSSOuZxCUn9HaP9JPp1rG93XxlWpSQJQIRiQKeAiYDmcBSEXlHVdd7TfYrYL2qniMiXYFNIjJPVWs/jseYMCqrqKxRn7/erc+v6gUzqp0wsFsiEwamkua2zx/cI4nk+JgwR25MYKE8IxgDbFXVbQAi8gpwHuCdCBToKM7hUSKwH/Dfv6wxzeRQSTkb97h1+bvyWbc7j817CimtcG7Kio+JYlCPjpw3qqen0D+ue0fiYqznS9M6hTIR9AJ2en3OBMb6TPMk8A6QBXQELlVVv33Risj1wPUAffv2bfJgTWTKLSzxdLlQVcXzY84hz4NMOifEkNYzmavH9/NU7fRP7RDWh5QY09RCmQj8/af4dnV6BrAKOBU4FviniHyhqvm1ZlSdA8wBp/fRpg3VtHWqSuaBIk/nalX1+XvyqztZ69UpniE9kzh3RPWRfo/kOKvPN21eKBNBJtDH63NvnCN/b1cDD6rTF/ZWEfkRGAR8F8K4TBtXXlHJD9mHWL87z6nacY/484qqO1k7tmsi445JcW7I6pnEkB5JdO4QG+bIjQmPUCaCpcBAEekP7AKmAzN8ptkBnAZ8ISLdgeOBbSGMybQxRaUV1fX57tH+xj0FnqddtXc7WTtrWA+3qWYSg45KsidZGeMlZIlAVctF5EbgY5zmo3NVdZ2I3OCOfxa4H/ibiHyPU5V0h6rmhCom07odPFxao+uFdVn5/JBdSNVDsJLiohnSM4krxh3taZ9/bNcORNsTroypV0jvI1DVD4APfIY96/U+C5gSyhhMy1XXs3FVld15xTX7z8/KZ9fB6k7WjkqKI61nUo3ulHt3blwna8ZEOntUpQkLf/3eR7cTjkntQHZhCQfch6aIQP8uHTwtdqqqd7okWidrxjSUParStCgPf7ypRhIA53GIP+Ye4sJRvUnrVV2f38E6WTMmpOw/zIRFllc1j7fyCuV/Lh7ezNEYE9nsKpppdm+tzKxzXM9O8c0YiTEG7IzANKPisgrue28987/dwTGpHcg6WERxefWN5PZsXGPCwxKBaRY7cg8za/5y1u7K54aTj+W2Kcfx3prd9mxcY1oASwQm5D5Zt4ffvrYaAZ67MoPJQ7oD9mxcY1oKSwQmZMoqKnn4403MWbKNYb2SefrydPqkJIQ7LGOMD0sEJiT25BVz08srWLr9AFeM68t/nz3Eumk2poWyRGCa3JdbcrjllZUUlVXw+PSRnDfSqn+MacksEZgmU1mpPLloK499upkBXRN55op0BnTrGO6wjDEBWCIwTWL/oVJufXUVSzZnc/7InvzpwmEkxNrPy5jWwP5TzRFb/tMBbpy/gtzCUh64YCgzxvS1zt+MaUUsEZhGU1Ve+Pd2/vTBBnp0iuONmScxrHdyuMMyxjSQJQLTKPnFZdzx+ho+XLuH0wd35y+XjCA5ISbcYRljGsESgWmw9Vn5zJq3nJ0HirjrzEFcP/EYqwoyphWzRGAaZMHSnfz+7bUkx8fw8nXjGNM/JdwhGWOOkCUCE5Si0gp+//ZaXl+eyfgBXXh8+ihS7eEwxrQJlghMQNuyC5k1bwWb9hZw86kDuOX044hqZ1VBxrQVlghMvd5fs5s73lhDTJTwwlWjmXR8t3CHZIxpYpYIjF+l5ZX86YMN/O2r7Yzq24mnZqTbQ2OMaaMsEZhadh0s4lfzVrBq50GuGd+fO88cRGy0PczOmLbKEoGpYdGmffz61VWUVyhPX57OWcN6hDskY0yIWSIwAFRUKo/9czNPLtrKoKM68swVJ9A/tUO4wzLGNANLBIbsghJueWUlX/2Qy7SM3tx33lB7doAxEcQSQYT7dlsuN728kryiMh66eDjTMvqEOyRjTDOzRBChKiuVOV9s4+GPN9E3JYEXrxnD4B5J4Q7LGBMGlggiUN7hMn772io+3bCPs4f14MGLhtExzjqMMyZSBdUmUEReFJFOXp87i8jckEVlQmZN5kHO/usXfL45m3vOGcKTM0ZZEjAmwgV7RjBcVQ9WfVDVAyIyKjQhmVBQVf7x7Q7uf3c9qYmxLPjliYzq2zncYRljWoBgE0E7EemsqgcARCSlAfOaMDtUUs5db37PO6uzmHR8Vx6bNpLOHWLDHZYxpoUItjD/C/CViLwOKDANeCDQTCIyFXgciAKeV9UHfcbfDlzuFctgoKuq7g8yLhPAlr0FzJy3gm3Zhdw25ThmTRpAO+swzhjjJahEoKovicgy4FRAgAtVdX1984hIFPAUMBnIBJaKyDve86nqw8DD7vTnAL+2JNB03lqZye/eXEuH9lH84z/HctKA1HCHZIxpgYJKBCIyDlinqk+6nzuKyFhV/bae2cYAW1V1mzvPK8B5QF0J5DLg5aAjN3UqLqvgvvfWM//bHYzpl8JfZ4yie1JcuMMyxrRQwfYk9gxQ6PX5kDusPr2AnV6fM91htYhIAjAVeKOuhYnI9SKyTESWZWdnBxV0JNqRe5iLn/2K+d/u4IaTj2X+dWMtCRhj6hXsNQJRVa36oKqVIhJoXn8V0epnGMA5wL/rqxZS1TnAHICMjIy6lhPRPlm3h9++thoBnrsyg8lDuoc7JGNMKxBsItgmIjdTfRYwC9gWYJ5MwLu/gt5AVh3TTseqhRqtrKKShz/exJwl2xjWK5mnL0+nT0pCuMMyxrQSwVYN3QCcBOzCKeDHAtcFmGcpMFBE+otILE5h/47vRCKSDJwMvB1s0KbanrxiZjz3DXOWbOOKcX157YYTLQkYYxok2FZD+3AKcgBEJB74D+C1euYpF5EbgY9xmo/OVdV1InKDO/5Zd9ILgE9U9VDjNiFyfbklh1teWUlRWQWPTx/JeSP9XoIxxph6iVfVf/0TOs1Bp+C07pkCfKmqF4cwtjplZGTosmXLwrHqFqGyUnly0VYe+3QzA7om8swV6Qzo1jHcYRljWjgRWa6qGb7DA54RiMhEYAZwNvAdMB44RlUPN3mUJqD9h0q59dVVLNmczfkje/KnC4eREGs3eRtjGq/eEkREMoEdOBeJb1fVAhH50ZJAeCz/6QA3zl9BbmEpD1wwlBlj+iJidwkbY45MoEPJN4DzgUuBChF5m7qbgJoQUVXm/ns7f/5gAz06xfHGzJMY1js53GEZY9qIelsNqeotQD/gUeAUYDPQVUSmiUhi6MMz+cVlzJq3gvvfW8+k47vx3o0TLAkYY5pUwMpl90ayfwH/EpEYnDuALwOeBqzzmhBan5XPrHnL2XmgiLvOHMT1E4+xqiBjTJNr0FVGVS0D3gXedZuQmhBZsHQnv397LcnxMbx83TjG9E8Jd0jGmDaq0c1NVLWoKQMxjqLSCn7/9lpeX57J+AFdeHz6KFIT24c7LGNMG2btDluQbdmFzJq3gk17C7j51AHccvpxRNmzA4wxIWaJoIV4f81u7nhjDTFRwgtXjWbS8d3CHZIxJkIEuo/gXeppLqqq5zZ5RBGmtLySP32wgb99tZ1RfTvx1Ix0enayyy/GmOYT6IzgEffvhcBRwD/cz5cB20MUU8TYdbCIX81bwaqdB7lmfH/uPHMQsdHB9gNojDFNo95EoKqfA4jI/ao60WvUuyKyJKSRtXGLNu3j16+uorxCefrydM4a1iPcIRljIlSw1wi6isgxXo+d7A90DV1YbVdFpfLYPzfz5KKtDDqqI89ccQL9UzuEOyxjTAQLNhH8GlgsIlUPo+kH/DIkEbVh+wqKueXlVXy9LZdpGb2577yhxMVEhTssY0yEC/Z5BB+JyEBgkDtoo6qWhC6stufbbbnc+PJK8ovKeOji4UzL6BN4JmOMaQaBWg2dqqr/EpELfUYdKyKo6pshjK1NqKxU/nfJNh75ZBN9UxJ46ZoxDO6RFO6wjDHGI9AZwck4/Qyd42ecApYI6pF3uIzfLFjFZxv3cfawHjx40TA6xsWEOyzTxpSVlZGZmUlxcXG4QzEtRFxcHL179yYmJrjyJlCroXvcv1c3QWwRZU3mQWbNW8He/GLuOWcIV53UzzqMMyGRmZlJx44d6dfPfmPG6bY+NzeXzMxM+vfvH9Q8gaqGfhNghY82IL6IoKr849sd3P/uelITY1nwyxMZ1bdzuMMybVhxcbElAeMhInTp0oXs7Oyg5wlUNWQPwm2AQyXl3PXm97yzOotJx3flsWkj6dwhNtxhmQhgScB4a+jvIVDV0B+OKJoIsmVvATPnrWBbdiG3TTmOWZMG0M46jDMR4ODBg8yfP59Zs2Y1eN6zzjqL+fPn06lTpzqnufvuu5k4cSKnn376EURp6hNU81ERiQP+E0gD4qqGq+o1IYqrVXlrZSa/e3MtHdpH8Y//HMtJA+x5PablWrhyFw9/vImsg0X07BTP7Wccz/mjejV6eQcPHuTpp5/2mwgqKiqIiqr7XpkPPvgg4PLvu+++RscWLuXl5URHt54+PYPt2ObvOH0NnQF8DvQGCkIVVGtRXFbBXW9+z69fXc2wXsm8f/MESwKmRVu4chd3vfk9uw4WoTj9Xd315vcsXLmr0cu88847+eGHHxg5ciS33347ixcv5pRTTmHGjBkMGzYMgPPPP58TTjiBtLQ05syZ45m3X79+5OTksH37dgYPHsx1111HWloaU6ZMoajIeeTJVVddxeuvv+6Z/p577iE9PZ1hw4axceNGALKzs5k8eTLp6en88pe/5OijjyYnJ6dWrDNnziQjI4O0tDTuuecez/ClS5dy0kknMWLECMaMGUNBQQEVFRXcdtttDBs2jOHDh/PXv/61RswAy5YtY9KkSQDce++9XH/99UyZMoUrr7yS7du3M2HCBNLT00lPT+err77yrO+hhx5i2LBhjBgxwvP9paene8Zv2bKFE044odH7pKGCTVkDVPUSETlPVV8UkfnAx6EMrKXbkXuYmfOWsy4rnxtOPpbbphxHdJR1GGfC6w/vrmN9Vn6d41fuOEhpRWWNYUVlFfzX62t4+bsdfucZ0jOJe85Jq3OZDz74IGvXrmXVqlUALF68mO+++461a9d6Wq3MnTuXlJQUioqKGD16NBdddBFdunSpsZwtW7bw8ssv89xzzzFt2jTeeOMNrrjiilrrS01NZcWKFTz99NM88sgjPP/88/zhD3/g1FNP5a677uKjjz6qkWy8PfDAA6SkpFBRUcFpp53GmjVrGDRoEJdeeimvvvoqo0ePJj8/n/j4eObMmcOPP/7IypUriY6OZv/+/XV+B1WWL1/Ol19+SXx8PIcPH+af//wncXFxbNmyhcsuu4xly5bx4YcfsnDhQr799lsSEhLYv38/KSkpJCcns2rVKkaOHMkLL7zAVVddFXB9TSXYRFDm/j0oIkOBPTjdTESkj9ft4bbXViPAc1dmMHlI93CHZExQfJNAoOGNNWbMmBpNF5944gneeustAHbu3MmWLVtqJYL+/fszcuRIAE444QS2b9/ud9kXXnihZ5o333RuZfryyy89y586dSqdO/tvqbdgwQLmzJlDeXk5u3fvZv369YgIPXr0YPTo0QAkJTk3fH766afccMMNniqelJTAj4s999xziY93upEvKyvjxhtvZNWqVURFRbF582bPcq+++moSEhJqLPfaa6/lhRde4NFHH+XVV1/lu+++C7i+phJsIpgjIp2B3wPvAInu+4hSVlHJwx9vYs6SbQzrlczTl6fTJyUh3GEZ41HfkTvA+Af/xa6DtZ8y26tTPK/+8sQmi6NDh+qOFBcvXsynn37K119/TUJCApMmTfJ781v79tWPZI2KivJUDdU1XVRUFOXl5YDTbDuQH3/8kUceeYSlS5fSuXNnrrrqKoqLi1FVv61s6hoeHR1NZaWTOH23w3u7H3vsMbp3787q1auprKwkLi6u3uVedNFFnjObE044oVaiDKV66zJEZL2I/D9gkaoeUNXPVfUYVe2mqv/bTDG2CHvyipnx3DfMWbKNK8b15bUbTrQkYFqd2884nnifjg7jY6K4/YzjG73Mjh07UlBQ9yXDvLw8OnfuTEJCAhs3buSbb75p9Lrq8rOf/YwFCxYA8Mknn3DgwIFa0+Tn59OhQweSk5PZu3cvH374IQCDBg0iKyuLpUuXAlBQUEB5eTlTpkzh2Wef9SSbqqqhfv36sXz5cgDeeOONOmPKy8ujR48etGvXjr///e9UVFQAMGXKFObOncvhw4drLDcuLo4zzjiDmTNncvXVzXsPb6BK7ctwjv4/EZFvReRWEYm4jvO/3JLD2U98wbqsfB6fPpI/nj/Meg01rdL5o3rx5wuH0atTPIJzJvDnC4cdUauhLl26MH78eIYOHcrtt99ea/zUqVMpLy9n+PDh/P73v2fcuHFHsAX+3XPPPXzyySekp6fz4Ycf0qNHDzp2rHkb1IgRIxg1ahRpaWlcc801jB8/HoDY2FheffVVbrrpJkaMGMHkyZMpLi7m2muvpW/fvgwfPpwRI0Ywf/58z7puueUWJkyYUG+LqFmzZvHiiy8ybtw4Nm/e7DlbmDp1Kueeey4ZGRmMHDmSRx55xDPP5ZdfjogwZcqUpv6K6iXBnFIBiMg44FLgImAr8LKqPhfC2OqUkZGhy5YtC/l6KiuVJxdt5bFPNzOgayLPXJHOgG52j51pWTZs2MDgwYPDHUZYlZSUEBUVRXR0NF9//TUzZ870XLxuTR555BHy8vK4//77j3hZ/n4XIrJcVTN8pw26oauqfgN8IyJvA48BTwJhSQTNYf+hUm59dRVLNmdz/sie/OnCYSTEtp52wcZEkh07djBt2jQqKyuJjY3luedaX9F0wQUX8MMPP/Cvf/2r2dcd7A1lo3GqiS7CeVbxHOC1IOabCjwORAHPq+qDfqaZBMwGYoAcVT05qMhDaPlPB7hx/gpyC0t54IKhzBjT127hN6YFGzhwICtXrgx3GEekqtVTOATqdO5PONVBB4BXgPGqmhnMgkUkCngKmAxkAktF5B1VXe81TSfgaWCqqu4QkW6N2oomoqrM/fd2/vzBBnp0iuONmScxrHdyOEMyxpiQC3RGUAKcqaqbG7HsMcBWr+ccvwKcB6z3mmYG8Kaq7gBQ1X2NWE+TyC8u447X1/Dh2j2cPrg7f7lkBMkJ9uwAY0zbF8pO53oBO70+ZwJjfaY5DogRkcU4PZ0+rqovHcE6G2V9Vj6z5i1n54Ei7jpzENdPPMaqgowxESNQ1dCPOE8iE/dvrUnc4bNV9Qk/43z5LiMaOAE4DYgHvhaRb/ydgYjI9cD1AH379q0v7AZZsHQnv397LcnxMbx83TjG9A9896AxxrQl9d5HoKr93RvIqv76vqqG+yYBcM4AvJ/Q3hvI8jPNR6p6SFVzgCXAiDpimaOqGaqa0bVr1+C3sA5FpRXc9tpq/uuNNWT068wHt0ywJGBMM0lMTAQgKyuLiy++2O80kyZNIlAz8dmzZ3tuzAKnW+uDBw82WZyRIthWQ/2B3apa7H6OA45S1e31zLYUGOjOuwuYjnNNwNvbwJMiEg3E4lQdPdagLQiSd9e7XTu2J0pgT0EJN586gFtOP44oe3aAiRRrFsBn90FeJiT3htPuhuHTwhJKz549PT2LNsbs2bO54oorPP32BNOtdUuiqqgq7dqFt8PKYNf+GuDdK1UlAZqPqmo5cCNOL6UbgAWquk5EbhCRG9xpNgAfAWuA73CamK5t2CYE5tv17r6CEnbnl3DdhP78ZsrxlgRM5FizAN69GfJ2Aur8ffdmZ3gj3XHHHTz99NOez/feey9/+ctfKCws5LTTTvN0Gf3222/Xmnf79u0MHToUgKKiIqZPn87w4cO59NJLa/Q15K/76CeeeIKsrCxOOeUUTjnlFKBmF9GPPvooQ4cOZejQocyePduzvrq6u/b27rvvMnbsWEaNGsXpp5/O3r17ASgsLOTqq6/2dE1d1cXERx99RHp6OiNGjOC0007zfA/edw0PHTqU7du3e2KYNWsW6enp7Ny5s0HdY0+YMKHGzXLjx49nzZo1Qe4t/4K9QypaVUurPqhqqYgEfAajqn4AfOAz7Fmfzw8DDwcZR6M8/PEmisoqag1/f80efnfWkFCu2pjm9eGdsOf7usdnLoWKkprDyorg7Rth+Yv+5zlqGJxZ6xYgj+nTp3Prrbd6HkyzYMECPvroI+Li4njrrbdISkoiJyeHcePGce6559bZEOOZZ54hISGBNWvWsGbNmhr98/vrPvrmm2/m0UcfZdGiRaSm1nwOyPLly3nhhRf49ttvUVXGjh3LySefTOfOnYPq7vpnP/sZ33zzDSLC888/z0MPPcRf/vIX7r//fpKTk/n+e+c7PnDgANnZ2Vx33XUsWbKE/v37B9Vd9aZNm3jhhRc8CbQh3WNfe+21/O1vf2P27Nls3ryZkpIShg8fHnCd9Qn2jCBbRM6t+iAi5wG1n/rQQmX56W2xvuHGtFm+SSDQ8CCMGjWKffv2kZWVxerVq+ncuTN9+/ZFVfnd737H8OHDOf3009m1a5fnyNqfJUuWeArk4cOH1yjcFixYQHp6OqNGjWLdunWsX7++rsUATrfUF1xwAR06dCAxMZELL7yQL774Agiuu+vMzEzOOOMMhg0bxsMPP8y6desApwvpX/3qV57pOnfuzDfffMPEiRM93W4H01310UcfXaPPJX/bt2nTplrdY0dHR3PJJZfw3nvvUVZWxty5c5vkuQXBnhHcAMwTkSfdz5nAlUe89mbSs1O83653e3aKD0M0xoRQPUfuADw21K0W8pHcB65+v9Grvfjii3n99dfZs2cP06dPB2DevHlkZ2ezfPlyYmJi6Nevn9/up735O1uoq/vo+tTXh1ow3V3fdNNN/OY3v+Hcc89l8eLF3HvvvZ7l+sYYTHfVULPLau/uqhvaPXZCQgKTJ0/m7bffZsGCBQEvqAcjqDMCVf1BVccBQ4A0VT1JVbce8dqbSSi63jWmVTrtbojxOQCKiXeGH4Hp06fzyiuv8Prrr3taAeXl5dGtWzdiYmJYtGgRP/30U73LmDhxIvPmzQNg7dq1nnrvurqPhrq7wJ44cSILFy7k8OHDHDp0iLfeeosJEyYEvT15eXn06uX0yPrii9VVZlOmTOHJJ5/0fD5w4AAnnngin3/+OT/++CNQs7vqFStWALBixQrPeF8N7R4bnIfY3HzzzYwePTqoM5BAgkoEIvInEemkqoWqWiAinUXkj0e89mYSiq53jWmVhk+Dc55wzgAQ5+85Txxxq6G0tDQKCgro1asXPXo4PdVffvnlLFu2jIyMDObNm8egQYPqXcbMmTMpLCxk+PDhPPTQQ4wZMwaou/togOuvv54zzzzTc7G4Snp6OldddRVjxoxh7NixXHvttYwaNSro7bn33nu55JJLmDBhQo3rD//93//NgQMHGDp0KCNGjGDRokV07dqVOXPmcOGFFzJixAguvfRSwHnQzP79+xk5ciTPPPMMxx13nN91NbR7bHCqtJKSkprsuQVBdUMtIitVdZTPsBWqml7XPKHUXN1QG9MaWDfUkScrK4tJkyaxcePGOpueNqQb6mAvFkeJiKdiTUTigfb1TG+MMSYEXnrpJcaOHcsDDzzQZPcfBHux+B/AZyLyAk43EdcAzd4nkDHGRLorr7ySK69s2rY6QSUCVX1IRNYAp+P0IXS/qn7cpJEYY4wJi4Y8oewj4CMR6QBcICLvq+rZoQvNGBOsupoamsgU7COIqwTbaihWRM4XkQXAbpzeQp8NMJsxphnExcWRm5vb4H9+0zapKrm5ucTFxQU9T6BuqCfjPKLyDGAR8HdgjKo2TZslY8wR6927N5mZmWRnZ4c7FNNCxMXF0bt376CnD1Q19DHwBfAzVf0RQEQeb3x4xpimFhMT4+newJjGCJQITsDpPvpTEdmG89ziqPpnMcYY05oEejDNSlW9Q1WPBe4FRgGxIvKh+8QwY4wxrVzQdyOo6r9V9UacZxHPBk4MVVDGGGOaT9DNR6uoaiXOtQO7j8AYY9qA8D4fzRhjTNhZIjDGmAgXdNWQiEQB3b3nUdUdoQjKGGNM8wkqEYjITcA9wF6qH2KvwJE9KNMYY0zYBXtGcAtwvKrmhjIYY4wxzS/YawQ7gbxQBmKMMSY8gj0j2AYsFpH3gZKqgar6aEiiMsYY02yCTQQ73Fes+zLGGNNGBPtgmj+EOhBjjDHhEagb6tmqequIvIvTSqgGVT03ZJEZY4xpFoHOCP7u/n0k1IEYY4wJj3oTgaoud/9+3jzhGGOMaW7B3lA2EPgzMATwPP9MVY8JUVzGGGOaSbD3EbwAPAOUA6cAL1FdbWSMMaYVCzYRxKvqZ4Co6k+qei9waujCMsYY01yCTQTFItIO2CIiN4rIBUC3QDOJyFQR2SQiW0XkTj/jJ4lInoiscl93NzB+Y4wxRyjYG8puBRKAm4H7caqHflHfDG5vpU8Bk4FMYKmIvKOq630m/UJV/6MhQRtjjGk6AROBW6BPU9XbgULg6iCXPQbYqqrb3OW8ApwH+CYCY4wxYVRv1ZCIRKtqBXCCiEgDl90Lp7O6KpnuMF8nishqEflQRNLqieV6EVkmIsuys7MbGIoxxpi6BDoj+A5IB1YCb4vIa8ChqpGq+mY98/pLHL53J68AjlbVQhE5C1gIDPS3MFWdA8wByMjIqHWXszHGmMYJ9hpBCpCL01JIcQp5BepLBJlAH6/PvYEs7wlUNd/r/Qci8rSIpKpqTpBxGWOMOUKBEkE3EfkNsJbqBFAl0FH5UmCgiPQHdgHTgRneE4jIUcBeVVURGYNTVWUPvzHGmGYUKBFEAYkEV81Tc6RquYjcCHzsLmeuqq4TkRvc8c8CFwMzRaQcKAKmq6pV+xhjTDOS+spdEVmhqunNGE9QMjIydNmyZeEOwxhjWhURWa6qGb7DA91Q1tCWQsYYY1qZQIngtGaJwhhjTNjUmwhUdX9zBWKMMSY8gu1ryBhjTBtlicAYYyKcJQJjjIlwlgiMMSbCWSIwxpgIZ4nAGGMinCUCY4yJcJYIjDEmwlkiMMaYCGeJwBhjIpwlAmOMiXCWCIwxJsJZIjDGmAhnicAYYyKcJQJjjIlwlgiMMSbCWSIwxpgIZ4nAGGMinCUCY4yJcJYIjDGmpVuzAB4bCvd2cv6uWdCki49u0qUZY1q/NQvgs/sgLxOSe8Npd8PwaeGOqm1TBa2EyvLqV4X7d91C+PRuKC92ps3bCe/e7Lxvov1iicAYU23NAqeQKStyPoeg0AlItWaBWFkOlRVQUVbzs+d9mc9nn4K01jxlfpbRAqZviLIiJ1lbIjDGHLGKcig6AIdz4HAufHRndRKoUlYE7/0adn5XT8Hb0ILae3qfcVoRnu+iSrsYaBftvqKq30fF1PzsGe81fXR7aNch+OmDWf77v/UfZ15mk22yJQJj2orKSig+CIf3O4V6rZef4cUHg1t2aSGsfaN2IRUVU7tAq1Eo+hR49U1f6+W9fO956lhGlJ/5653eT8Er7UAklHup4b6c7ZyZ+Uru3WSrsERgTEukCiUFdRfg/gr3ov1OPbM/Ue2hQyokpEBCF+jUx/nrebnD37weCvfWnj+5D/x6bWi32fh32t01q+sAYuKd4U3EEoExzaGsKPDR+aGcmsMry/wvq110zUK82yCfQt2rYK96xSQEd6Q75Y8hL3RMA1VdBwjhBXxLBMY0VHmpc/QdTNVL1bCyw3UsTCC+c3WB3bkf9Er3U7B7Fe5xyaGrvmiGQsc0wvBpId0HlghMZKusgKKDXgV3TuCCvSS/7uW1T64usBOPgm5ptY/OvV/xnZx66pYkxIWOaXlCmghEZCrwOBAFPK+qD9Yx3WjgG+BSVX09lDGZFqSp26urQnFegHp1n+FFBwD1v7yYhJpH4inHQEKq/6qXhC7OkX10bOPjNyZMQpYIRCQKeAqYDGQCS0XkHVVd72e6/wE+DlUspgUK1F5dFUoPBTg693OxtK722FGxNatYjhpaf716fArEJjTPd2FMmIXyjGAMsFVVtwGIyCvAecB6n+luAt4ARocwFtPSfHqv//bqC2c54w7nVt9J6Uva1SzAUwdAwtj6C/bYxJbXLNCYFiKUiaAX4N34NRMY6z2BiPQCLgBOJUAiEJHrgesB+vbt26SBmhAqK4LsjbBvA+xdB/vWw971ULjH//SVZXDMKf6rXqqaP7ZPhnbWTZYxTSWUicDf4ZdvZexs4A5VrZAAR2uqOgeYA5CRkVFHpa4Jm8oK2P8j7FvnFPT73Nf+bdVt26PjoOvxcOypsOl9pz7fV3IfOP+p5o3dmAgXykSQCfTx+twbyPKZJgN4xU0CqcBZIlKuqgtDGJc5EqpQsMcp8PdtcAv9dZC9qboqR9o5F1a7DYahF0P3IU7rmZT+1S1kfK8RgLVXNyZMQpkIlgIDRaQ/sAuYDszwnkBV+1e9F5G/Ae9ZEmhBivOdwt5zlO++LzpQPU3iUU5BP/pa6J7mFP5dBzmFen2svboxLUbIEoGqlovIjTitgaKAuaq6TkRucMc/G6p1mwYqL4WczdXVOVVVO979m8R2dAr8Iec5R/fdh0C3IU6dfWNZe3VjWgRRbX3V7RkZGbps2bJwh9H6VFbCwZ9qH+XnbqludtkuBlKPqy7ouw1x3if3sVY3xrRyIrJcVTN8h9udxW3VoZzqVjpVR/nZG51eJKt0Otqpzhl0llvgp0GXAU6vjMaYiGGJoLUrPeQU8FXVOXvdi7iH9lVPk9DFKehHXVF9lN9tELTvGL64jTEthiWC1qKiHPb/4HWU77bLP7AdT6vcmATnQu1xU7yqddKgQ1er1jHG1MkSQUujCvm7at+AlbMJKkqdaSQKuhwLPUbAyBluoT8YOve3G62MMQ1miSCcig54FfgbquvzvW+0SurlFPTHnuI2zxziXMyNiQtf3MaYNsUSQXMoK3aO6H2P8gu87q9rn+y0zvHcgOUe5cd3Dl/cxpiIYImgKVVWOHX2nrb47pF+7g/VD+SOinW6Weg/oboOv9sQSOpp9fjGmLCwRNAYqlC4r3Y3C/s2QnlVlwniPG2qexoMOb/6KD/lWOch28YY00JYiRRISYFTwPt2pnY4t3qaDt2cgj7j6uobsLoOgtgO4YvbGGOCFDmJINDTsCrKIGeLTzcL6+DgjuppYjo49faDzna6Weg22G2emdr822OMMU0kMhKBv6dhvf0r2PiB0xvmvg1OXzuVZc74dtHQZSD0Hg3pV1b3rZPc15pnGmPanMhIBJ/dV/tpWBWlsP4tpw+dbkPcm7Dco/zUgRDdPjyxGmNMM4uMRJCXWccIgV+vbdZQjDGmpYmMeo7k3g0bbowxESQyEsFpd9d+UIo9DcsYY4BISQTDp8E5TzjXAxDn7zlP2ENRjDGGSLlGAPY0LGOMqUNknBEYY4ypkyUCY4yJcJYIjDEmwlkiMMaYCGeJwBhjIpyoarhjaDARyQZ+auTsqUBOE4YTTm1lW9rKdoBtS0vVVrblSLfjaFXt6juwVSaCIyEiy1Q1I9xxNIW2si1tZTvAtqWlaivbEqrtsKohY4yJcJYIjDEmwkViIpgT7gCaUFvZlrayHWDb0lK1lW0JyXZE3DUCY4wxNUXiGYExxhgvlgiMMSbCtdlEICJTRWSTiGwVkTv9jBcRecIdv0ZE0sMRZyBBbMckEckTkVXuq0U+ZEFE5orIPhHx+0i41rI/IKhtaRX7BEBE+ojIIhHZICLrROQWP9O0+H0T5Ha0iv0iInEi8p2IrHa35Q9+pmnafaKqbe4FRAE/AMcAscBqYIjPNGcBHwICjAO+DXfcjdyOScB74Y41iG2ZCKQDa+sY3+L3RwO2pVXsEzfWHkC6+74jsLmV/q8Esx2tYr+433Oi+z4G+BYYF8p90lbPCMYAW1V1m6qWAq8A5/lMcx7wkjq+ATqJSI/mDjSAYLajVVDVJcD+eiZpDfsDCGpbWg1V3a2qK9z3BcAGoJfPZC1+3wS5Ha2C+z0Xuh9j3Jdvq54m3SdtNRH0AnZ6fc6k9o8imGnCLdgYT3RPIz8UkbTmCa3JtYb90RCtbp+ISD9gFM4RqLdWtW/q2Q5oJftFRKJEZBWwD/inqoZ0n7TVJ5SJn2G+GTWYacItmBhX4PQfUigiZwELgYGhDiwEWsP+CFar2ycikgi8Adyqqvm+o/3M0iL3TYDtaDX7RVUrgJEi0gl4S0SGqqr3Nakm3Sdt9YwgE+jj9bk3kNWIacItYIyqml91GqmqHwAxIpLafCE2mdawP4LS2vaJiMTgFJ7zVPVNP5O0in0TaDta234BUNWDwGJgqs+oJt0nbTURLAUGikh/EYkFpgPv+EzzDnCle/V9HJCnqrubO9AAAm6HiBwlIuK+H4OzT3ObPdIj1xr2R1Ba0z5x4/w/YIOqPlrHZC1+3wSzHa1lv4hIV/dMABGJB04HNvpM1qT7pE1WDalquYjcCHyM0/JmrqquE5Eb3PHPAh/gXHnfChwGrg5XvHUJcjsuBmaKSDlQBExXt1lBSyIiL+O02kgVkUzgHpyLYK1mf1QJYltaxT5xjQd+Dnzv1kkD/A7oC61q3wSzHa1lv/QAXhSRKJxktUBV3wtl+WVdTBhjTIRrq1VDxhhjgmSJwBhjIpwlAmOMiXCWCIwxJsJZIjDGmAhnicAYP0SkwquXylXip+fXI1h2P6mj51JjwqFN3kdgTBMoUtWR4Q7CmOZgZwTGNICIbBeR/3H7i/9ORAa4w48Wkc/cvuE/E5G+7vDuIvKW29HZahE5yV1UlIg85/Y3/4l7B6kxYWGJwBj/4n2qhi71GpevqmOAJ4HZ7rAncboFHg7MA55whz8BfK6qI3CeYbDOHT4QeEpV04CDwEUh3Rpj6mF3Fhvjh4gUqmqin+HbgVNVdZvbydkeVe0iIjlAD1Utc4fvVtVUEckGeqtqidcy+uF0LTzQ/XwHEKOqf2yGTTOmFjsjMKbhtI73dU3jT4nX+wrsep0JI0sExjTcpV5/v3bff4XTOyzA5cCX7vvPgJngedhIUnMFaUyw7CjEGP/ivXqxBPhIVauakLYXkW9xDqQuc4fdDMwVkduBbKp7g7wFmCMi/4lz5D8TaFFdOBtj1wiMaQD3GkGGquaEOxZjmopVDRljTISzMwJjjIlwdkZgjDERzhKBMcZEOEsExhgT4SwRGGNMhLNEYIwxEe7/A0SkDURhcSbmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(model.history.history['accuracy'], marker='o', label='training accuracy')\n",
    "plt.plot(model.history.history['val_accuracy'], marker='o', label='validation accuracy')\n",
    "plt.title('Training Accuracy and Validation Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Acc|Valid Acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has similar results to the baseline. It seems like adding those dense layers should do something, so I may keep them going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing hyperparameters via grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining grid search components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homemade grid search, as the sklearn wrapper does not work with our current data input/output.\n",
    "\n",
    "This generator works with square images only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(image_size, path, preprocess_func=None, split_off_for_val=0.0,\n",
    "                   split_segment = None, shuf = True, bat_size = 80):\n",
    "    \n",
    "    this_datagen = ImageDataGenerator(preprocessing_function = preprocess_func, validation_split = split_off_for_val)\n",
    "    #  note: ImageDataGenerator does not appear to have a parameter for random seeds. Be wary of train/val overlap\n",
    "    #  note: train/val/test split does not currently work\n",
    "    this_generator = this_datagen.flow_from_directory(path, \n",
    "                                                     target_size=image_size,\n",
    "                                                     subset = split_segment, #  None|'training'|'validation'\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size= bat_size,\n",
    "                                                     class_mode='categorical',\n",
    "                                                     shuffle=shuf)\n",
    "    \n",
    "    return this_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_importer(im_side_len = 80, batch_size = 80):\n",
    "    \n",
    "    train_data = data_generator(image_size = [im_side_len, im_side_len],\n",
    "                                path = 'data/grassnoted split/asl_alphabet_train',\n",
    "                                bat_size = batch_size\n",
    "                               )\n",
    "    validation_data = data_generator(image_size = [im_side_len, im_side_len],\n",
    "                                     path = 'data/grassnoted split/asl_alphabet_validation',\n",
    "                                     bat_size = batch_size\n",
    "                                    )\n",
    "    test_data = data_generator(image_size = [im_side_len, im_side_len],\n",
    "                               path = 'data/grassnoted split/asl_alphabet_test',\n",
    "                               bat_size = batch_size\n",
    "                              )\n",
    "    \n",
    "    return train_data, validation_data, test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker(im_side_len = 80):\n",
    "    \n",
    "    #assembling baseline model with three added dense layers (see above)\n",
    "    # note: these layers are given different names by the system (i.e. the first is dense_4)\n",
    "    #       but this does not seem to cause structural difference between models\n",
    "    \n",
    "    #transfer learning from experienced model\n",
    "    experienced_model = MobileNetV2(weights='imagenet', include_top=False, input_shape = (im_side_len,im_side_len,3))\n",
    "    \n",
    "    # Assign the output of this base_model to a variable:\n",
    "    base_model_out = experienced_model.output\n",
    "\n",
    "    # Add a pooling layer:\n",
    "    base_model_out = GlobalAveragePooling2D()(base_model_out)\n",
    "\n",
    "    # Add 3 dense layers so that the model can learn aspects of our new dataset \n",
    "    # and classify for better results.\n",
    "    base_model_out = Dense(243, activation='relu')(base_model_out) \n",
    "    base_model_out = Dense(243, activation='relu')(base_model_out)\n",
    "    base_model_out = Dense(81, activation='relu')(base_model_out)\n",
    "\n",
    "    # using a softmax base_model_out activation function:\n",
    "    preds = Dense(29, activation='softmax')(base_model_out)\n",
    "\n",
    "\n",
    "    # Instantiate our final model, where we specify what are the inputs and \n",
    "    # the outputs will look like\n",
    "    model = Model(inputs = experienced_model.input, \n",
    "                  outputs = preds)\n",
    "\n",
    "    \n",
    "    #The layers from MobileNetV2 will not be trained\n",
    "    for layer in model.layers[:154]:\n",
    "        layer.trainable=False\n",
    "\n",
    "    for layer in model.layers[154:]:\n",
    "        print(layer.name)\n",
    "        layer.trainable=True\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_compiler(model, loss_func = 'categorical_crossentropy', optim_choice = 'Adam', value_to_max = ['accuracy']):\n",
    "    \n",
    "    model.compile(loss = loss_func, #loss function\n",
    "                  optimizer = optim_choice,\n",
    "                  metrics = value_to_max) #value to maximize\n",
    "    compiled_model = model\n",
    "    return compiled_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fitter(compiled_model, train_data, validation_data, epochs = 1):  \n",
    "    \n",
    "    #step size based on batch size\n",
    "    step_size_train = train_data.n//train_data.batch_size + 1\n",
    "    \n",
    "    print(step_size_train)\n",
    "    \n",
    "    model = compiled_model\n",
    "    \n",
    "    model.fit_generator(generator = train_data,\n",
    "                        validation_data = validation_data,\n",
    "                        steps_per_epoch = step_size_train,\n",
    "                        epochs = 1,\n",
    "                        verbose = 1)\n",
    "    \n",
    "    training_accuracy = model.history.history['categorical_accuracy']\n",
    "    validation_accuracy = model.history.history['val_categorical_accuracy']\n",
    "    \n",
    "    return training_accuracy, validation_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42630 images belonging to 29 classes.\n",
      "Found 18270 images belonging to 29 classes.\n",
      "Found 26100 images belonging to 29 classes.\n",
      "global_average_pooling2d_6\n",
      "dense_24\n",
      "dense_25\n",
      "dense_26\n",
      "dense_27\n",
      "533 <class 'int'>\n",
      "533/533 [==============================] - 224s 415ms/step - loss: 1.7290 - accuracy: 0.4818 - val_loss: 2.3643 - val_accuracy: 0.4377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6625146865844727], [0.4377121031284332])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, validation_data, test_data = data_importer(im_side_len = 96)\n",
    "model_a = model_maker(im_side_len = 96)\n",
    "compiled_model_a = model_compiler(model = model_a)\n",
    "model_fitter(compiled_model = compiled_model_a, train_data = train_data, validation_data = validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'param1': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b              c\n",
       "0  0  0             {}\n",
       "1  1  1  {'param1': 1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[0,0,{}]]\n",
    "a.append([1,1,{'param1' : 1}])\n",
    "a = np.array(a)\n",
    "pd.DataFrame(a, columns = ['a', 'b','c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input parameters to search through as lists\n",
    "def grid_search(batch_sizes, image_sizes, loss_funcs, optims, values_to_max, epochs):\n",
    "    a = []\n",
    "    for i in batch_sizes:\n",
    "        for j in image_sizes:\n",
    "            train_data, validation_data, test_data = data_importer(batch_size = i, im_side_len = j)\n",
    "            model = model_maker(im_side_len = j)\n",
    "            for k in loss_funcs:\n",
    "                print(k)\n",
    "                for l in optims:\n",
    "                    print(l)\n",
    "                    for m in values_to_max:\n",
    "                        print(m)\n",
    "                        compiled_model = model_compiler(loss_func = k, optim_choice = l, value_to_max = m, model = model)\n",
    "                        for n in epochs:\n",
    "                            print(n)\n",
    "                            train_acc, valid_acc = model_fitter(epochs = n,compiled_model = compiled_model, train_data = train_data, validation_data = validation_data)\n",
    "                            \n",
    "                            param_str = f'batch size : {i}\\n image size {j} \\n loss function {k} \\n optimizer {l} \\n value to maximize {m} \\n epochs {n}'\n",
    "\n",
    "                            a.append([train_acc[0], valid_acc[0], param_str])\n",
    "    return a\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42630 images belonging to 29 classes.\n",
      "Found 18270 images belonging to 29 classes.\n",
      "Found 26100 images belonging to 29 classes.\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "global_average_pooling2d_2\n",
      "dense_8\n",
      "dense_9\n",
      "dense_10\n",
      "dense_11\n",
      "categorical_crossentropy\n",
      "Adam\n",
      "accuracy\n",
      "1\n",
      "1066 <class 'int'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h\\.conda\\envs\\deeplearningcopy\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066/1066 [==============================] - 155s 141ms/step - loss: 1.9241 - accuracy: 0.4129 - val_loss: 2.6722 - val_accuracy: 0.2836\n",
      "Found 42630 images belonging to 29 classes.\n",
      "Found 18270 images belonging to 29 classes.\n",
      "Found 26100 images belonging to 29 classes.\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "global_average_pooling2d_3\n",
      "dense_12\n",
      "dense_13\n",
      "dense_14\n",
      "dense_15\n",
      "categorical_crossentropy\n",
      "Adam\n",
      "accuracy\n",
      "1\n",
      "1066 <class 'int'>\n",
      "1066/1066 [==============================] - 154s 139ms/step - loss: 1.6717 - accuracy: 0.4832 - val_loss: 2.6939 - val_accuracy: 0.3037\n"
     ]
    }
   ],
   "source": [
    "test_1 = grid_search(batch_sizes = [40], \n",
    "                        image_sizes = [40, 60], \n",
    "                        loss_funcs = ['categorical_crossentropy'], \n",
    "                        optims = ['Adam'], \n",
    "                        values_to_max = ['accuracy'], \n",
    "                        epochs = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1_df = pd.DataFrame(test_1, columns = ['train_acc', 'valid_acc', 'param_str'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size : 40\n",
      " image size 40 \n",
      " loss function categorical_crossentropy \n",
      " optimizer Adam \n",
      " value to maximize accuracy \n",
      " epochs 1\n"
     ]
    }
   ],
   "source": [
    "print(test_1_df.iloc[0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a larger grid search with 3 epochs and, due to time constraints, one small batch size, one small image size, and hyperparameters chosen from research rather than every available combination of options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizer**\n",
    "\n",
    "**Loss function** is tied in with the choice of activation function. For this multi-class-classification problem, softmax is being used as a final activation function. According to [this blog post](https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/), this should be paired with a categorical-crossentropy function. As the classification task does not use a sparse matrix, sparse_categorical_crossentropy will not be used as a loss function.\n",
    "\n",
    "**Optimization Metric** lets the network know how well it's doing. Having multiple options here results in multiple different metrics being returned, which makes comparison difficult. In this particular task, classification with classes in the tens, the metric of choice will be categorical_accuracy. Find out more [in this post post](https://neptune.ai/blog/keras-metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42630 images belonging to 29 classes.\n",
      "Found 18270 images belonging to 29 classes.\n",
      "Found 26100 images belonging to 29 classes.\n",
      "global_average_pooling2d_13\n",
      "dense_49\n",
      "dense_50\n",
      "dense_51\n",
      "dense_52\n",
      "categorical_crossentropy\n",
      "SGD\n",
      "categorical_accuracy\n",
      "4\n",
      "711\n",
      "711/711 [==============================] - 239s 331ms/step - loss: 2.7400 - categorical_accuracy: 0.2397 - val_loss: 2.8192 - val_categorical_accuracy: 0.2209\n",
      "RMSprop\n",
      "categorical_accuracy\n",
      "4\n",
      "711\n",
      "711/711 [==============================] - 249s 345ms/step - loss: 1.4407 - categorical_accuracy: 0.5536 - val_loss: 2.7043 - val_categorical_accuracy: 0.4172\n",
      "Adadelta\n",
      "categorical_accuracy\n",
      "4\n",
      "711\n",
      "711/711 [==============================] - 252s 350ms/step - loss: 0.4868 - categorical_accuracy: 0.8331 - val_loss: 2.5105 - val_categorical_accuracy: 0.4566\n",
      "Adam\n",
      "categorical_accuracy\n",
      "4\n",
      "711\n",
      "711/711 [==============================] - 265s 365ms/step - loss: 0.4231 - categorical_accuracy: 0.8509 - val_loss: 2.6641 - val_categorical_accuracy: 0.4701\n",
      "Adagrad\n",
      "categorical_accuracy\n",
      "4\n",
      "711\n",
      "711/711 [==============================] - 272s 378ms/step - loss: 0.1892 - categorical_accuracy: 0.9372 - val_loss: 2.7058 - val_categorical_accuracy: 0.5265\n",
      "Adamax\n",
      "categorical_accuracy\n",
      "4\n",
      "711\n",
      "711/711 [==============================] - 274s 380ms/step - loss: 0.1925 - categorical_accuracy: 0.9318 - val_loss: 2.9424 - val_categorical_accuracy: 0.5349\n",
      "Nadam\n",
      "categorical_accuracy\n",
      "4\n",
      "711\n",
      "711/711 [==============================] - 280s 387ms/step - loss: 0.2334 - categorical_accuracy: 0.9165 - val_loss: 3.1360 - val_categorical_accuracy: 0.5096\n",
      "Ftrl\n",
      "categorical_accuracy\n",
      "4\n",
      "711\n",
      "711/711 [==============================] - 276s 382ms/step - loss: 3.3352 - categorical_accuracy: 0.0418 - val_loss: 3.3673 - val_categorical_accuracy: 0.0345\n"
     ]
    }
   ],
   "source": [
    "test_2 = grid_search(batch_sizes = [60], \n",
    "                        image_sizes = [96], #  original train images are 200x200 but kernel may crash\n",
    "                        loss_funcs = ['categorical_crossentropy'], \n",
    "                        optims = ['SGD', 'RMSprop', 'Adadelta', 'Adam', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl'], \n",
    "                        values_to_max = ['categorical_accuracy'], \n",
    "                        epochs = [4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2_df = pd.DataFrame(test_2,\n",
    "             columns = ['train_acc', 'valid_acc', 'param_str'])\n",
    "test_2_df.to_csv('data/test_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>param_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.375557</td>\n",
       "      <td>0.220909</td>\n",
       "      <td>batch size : 60\\n image size 96 \\n loss functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.665588</td>\n",
       "      <td>0.417241</td>\n",
       "      <td>batch size : 60\\n image size 96 \\n loss functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.456596</td>\n",
       "      <td>batch size : 60\\n image size 96 \\n loss functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.470060</td>\n",
       "      <td>batch size : 60\\n image size 96 \\n loss functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.941356</td>\n",
       "      <td>0.526546</td>\n",
       "      <td>batch size : 60\\n image size 96 \\n loss functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.937040</td>\n",
       "      <td>0.534921</td>\n",
       "      <td>batch size : 60\\n image size 96 \\n loss functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.918836</td>\n",
       "      <td>0.509633</td>\n",
       "      <td>batch size : 60\\n image size 96 \\n loss functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.033404</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>batch size : 60\\n image size 96 \\n loss functi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_acc  valid_acc                                          param_str\n",
       "0   0.375557   0.220909  batch size : 60\\n image size 96 \\n loss functi...\n",
       "1   0.665588   0.417241  batch size : 60\\n image size 96 \\n loss functi...\n",
       "2   0.850317   0.456596  batch size : 60\\n image size 96 \\n loss functi...\n",
       "3   0.867347   0.470060  batch size : 60\\n image size 96 \\n loss functi...\n",
       "4   0.941356   0.526546  batch size : 60\\n image size 96 \\n loss functi...\n",
       "5   0.937040   0.534921  batch size : 60\\n image size 96 \\n loss functi...\n",
       "6   0.918836   0.509633  batch size : 60\\n image size 96 \\n loss functi...\n",
       "7   0.033404   0.034483  batch size : 60\\n image size 96 \\n loss functi..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_2_df = pd.read_csv('data/test_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing hyperparameters in the loss function and metric categories that caused errors, I ended up just testing optimizers. This means the results will lack in context quite a lot. \n",
    "For the sake of time, the optimizer with the highest validation accuracy given the other hyperparameters will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest validation accuracy among given options: 0.5349206328392029 batch size : 60\n",
      " image size 96 \n",
      " loss function categorical_crossentropy \n",
      " optimizer Adamax \n",
      " value to maximize categorical_accuracy \n",
      " epochs 4\n"
     ]
    }
   ],
   "source": [
    "print('Highest validation accuracy among given options:', test_2_df.iloc[5,1], test_2_df.iloc[5,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By my current understanding, the most important hyperparameter in Adamax is the learning rate. This may be best tweaked further down the line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this test, a variety of batch sizes will be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42630 images belonging to 29 classes.\n",
      "Found 18270 images belonging to 29 classes.\n",
      "Found 26100 images belonging to 29 classes.\n",
      "global_average_pooling2d_16\n",
      "dense_61\n",
      "dense_62\n",
      "dense_63\n",
      "dense_64\n",
      "categorical_crossentropy\n",
      "Adamax\n",
      "categorical_accuracy\n",
      "4\n",
      "4264\n",
      "4262/4264 [============================>.] - ETA: 0s - loss: 1.6801 - categorical_accuracy: 0.4981WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 4264 batches). You may need to use the repeat() function when building your dataset.\n",
      "4264/4264 [==============================] - 336s 78ms/step - loss: 1.6799 - categorical_accuracy: 0.4981 - val_loss: 2.3575 - val_categorical_accuracy: 0.4278\n",
      "Found 42630 images belonging to 29 classes.\n",
      "Found 18270 images belonging to 29 classes.\n",
      "Found 26100 images belonging to 29 classes.\n",
      "global_average_pooling2d_17\n",
      "dense_65\n",
      "dense_66\n",
      "dense_67\n",
      "dense_68\n",
      "categorical_crossentropy\n",
      "Adamax\n",
      "categorical_accuracy\n",
      "4\n",
      "1066\n",
      "1066/1066 [==============================] - 274s 254ms/step - loss: 1.9228 - categorical_accuracy: 0.4429 - val_loss: 2.3953 - val_categorical_accuracy: 0.3806\n",
      "Found 42630 images belonging to 29 classes.\n",
      "Found 18270 images belonging to 29 classes.\n",
      "Found 26100 images belonging to 29 classes.\n",
      "global_average_pooling2d_18\n",
      "dense_69\n",
      "dense_70\n",
      "dense_71\n",
      "dense_72\n",
      "categorical_crossentropy\n",
      "Adamax\n",
      "categorical_accuracy\n",
      "4\n",
      "711\n",
      "711/711 [==============================] - 257s 356ms/step - loss: 2.0089 - categorical_accuracy: 0.4365 - val_loss: 2.3456 - val_categorical_accuracy: 0.3939\n",
      "Found 42630 images belonging to 29 classes.\n",
      "Found 18270 images belonging to 29 classes.\n",
      "Found 26100 images belonging to 29 classes.\n",
      "global_average_pooling2d_19\n",
      "dense_73\n",
      "dense_74\n",
      "dense_75\n",
      "dense_76\n",
      "categorical_crossentropy\n",
      "Adamax\n",
      "categorical_accuracy\n",
      "4\n",
      "474\n",
      "474/474 [==============================] - 251s 522ms/step - loss: 2.0881 - categorical_accuracy: 0.4092 - val_loss: 2.4087 - val_categorical_accuracy: 0.3745\n"
     ]
    }
   ],
   "source": [
    "test_3 = grid_search(batch_sizes = [10, 40, 60, 90], \n",
    "                        image_sizes = [96], #  original train images are 200x200 but kernel may crash\n",
    "                        loss_funcs = ['categorical_crossentropy'], \n",
    "                        optims = ['Adamax'], \n",
    "                        values_to_max = ['categorical_accuracy'], \n",
    "                        epochs = [4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3_df = pd.DataFrame(test_3,\n",
    "             columns = ['train_acc', 'valid_acc', 'param_str'])\n",
    "test_3_df.to_csv('data/test_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>param_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666268</td>\n",
       "      <td>0.427750</td>\n",
       "      <td>batch size : 10\\n image size 96 \\n loss functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.616749</td>\n",
       "      <td>0.380624</td>\n",
       "      <td>batch size : 40\\n image size 96 \\n loss functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.607014</td>\n",
       "      <td>0.393924</td>\n",
       "      <td>batch size : 60\\n image size 96 \\n loss functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.577082</td>\n",
       "      <td>0.374548</td>\n",
       "      <td>batch size : 90\\n image size 96 \\n loss functi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_acc  valid_acc                                          param_str\n",
       "0   0.666268   0.427750  batch size : 10\\n image size 96 \\n loss functi...\n",
       "1   0.616749   0.380624  batch size : 40\\n image size 96 \\n loss functi...\n",
       "2   0.607014   0.393924  batch size : 60\\n image size 96 \\n loss functi...\n",
       "3   0.577082   0.374548  batch size : 90\\n image size 96 \\n loss functi..."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_3_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size 10 seems to have generated a warning, so I will go with the runner-up, batch size 60."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this test, a variety of image sizes will be considered.\n",
    "\n",
    "All images will be square.\n",
    "\n",
    "Most will be selected as they are more compatible with MobileNetV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42630 images belonging to 29 classes.\n",
      "Found 18270 images belonging to 29 classes.\n",
      "Found 26100 images belonging to 29 classes.\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "global_average_pooling2d_20\n",
      "dense_77\n",
      "dense_78\n",
      "dense_79\n",
      "dense_80\n",
      "categorical_crossentropy\n",
      "Adamax\n",
      "categorical_accuracy\n",
      "4\n",
      "711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h\\.conda\\envs\\deeplearningcopy\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711/711 [==============================] - 143s 196ms/step - loss: 1.9260 - categorical_accuracy: 0.4307 - val_loss: 2.6533 - val_categorical_accuracy: 0.3192\n",
      "Found 42630 images belonging to 29 classes.\n",
      "Found 18270 images belonging to 29 classes.\n",
      "Found 26100 images belonging to 29 classes.\n",
      "global_average_pooling2d_21\n",
      "dense_81\n",
      "dense_82\n",
      "dense_83\n",
      "dense_84\n",
      "categorical_crossentropy\n",
      "Adamax\n",
      "categorical_accuracy\n",
      "4\n",
      "711\n",
      "711/711 [==============================] - 237s 329ms/step - loss: 1.9791 - categorical_accuracy: 0.4370 - val_loss: 2.4684 - val_categorical_accuracy: 0.3839\n",
      "Found 42630 images belonging to 29 classes.\n",
      "Found 18270 images belonging to 29 classes.\n",
      "Found 26100 images belonging to 29 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
      "9412608/9406464 [==============================] - 4s 0us/step\n",
      "global_average_pooling2d_22\n",
      "dense_85\n",
      "dense_86\n",
      "dense_87\n",
      "dense_88\n",
      "categorical_crossentropy\n",
      "Adamax\n",
      "categorical_accuracy\n",
      "4\n",
      "711\n",
      "711/711 [==============================] - 404s 564ms/step - loss: 1.9164 - categorical_accuracy: 0.4689 - val_loss: 2.1661 - val_categorical_accuracy: 0.4488\n",
      "Found 42630 images belonging to 29 classes.\n",
      "Found 18270 images belonging to 29 classes.\n",
      "Found 26100 images belonging to 29 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
      "9412608/9406464 [==============================] - 4s 0us/step\n",
      "global_average_pooling2d_23\n",
      "dense_89\n",
      "dense_90\n",
      "dense_91\n",
      "dense_92\n",
      "categorical_crossentropy\n",
      "Adamax\n",
      "categorical_accuracy\n",
      "4\n",
      "711\n",
      "711/711 [==============================] - 624s 873ms/step - loss: 1.2878 - categorical_accuracy: 0.6614 - val_loss: 1.6737 - val_categorical_accuracy: 0.5574\n",
      "Found 42630 images belonging to 29 classes.\n",
      "Found 18270 images belonging to 29 classes.\n",
      "Found 26100 images belonging to 29 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_192_no_top.h5\n",
      "9412608/9406464 [==============================] - 3s 0us/step\n",
      "global_average_pooling2d_24\n",
      "dense_93\n",
      "dense_94\n",
      "dense_95\n",
      "dense_96\n",
      "categorical_crossentropy\n",
      "Adamax\n",
      "categorical_accuracy\n",
      "4\n",
      "711\n",
      "711/711 [==============================] - 883s 1s/step - loss: 1.9123 - categorical_accuracy: 0.4781 - val_loss: 2.0835 - val_categorical_accuracy: 0.4739\n"
     ]
    }
   ],
   "source": [
    "test_4 = grid_search(batch_sizes = [60], \n",
    "                        image_sizes = [60, 96, 128, 160, 192], #  original train images are 200x200 but kernel may crash\n",
    "                        loss_funcs = ['categorical_crossentropy'], \n",
    "                        optims = ['Adamax'], \n",
    "                        values_to_max = ['categorical_accuracy'], \n",
    "                        epochs = [4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_4_df = pd.DataFrame(test_4,\n",
    "             columns = ['train_acc', 'valid_acc', 'param_str'])\n",
    "test_4_df.to_csv('data/test_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>param_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.559442</td>\n",
       "      <td>0.319212</td>\n",
       "      <td>batch size : 60\\n image size 60 \\n loss functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.607131</td>\n",
       "      <td>0.383853</td>\n",
       "      <td>batch size : 60\\n image size 96 \\n loss functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.642834</td>\n",
       "      <td>0.448823</td>\n",
       "      <td>batch size : 60\\n image size 128 \\n loss funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.818625</td>\n",
       "      <td>0.557362</td>\n",
       "      <td>batch size : 60\\n image size 160 \\n loss funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.672038</td>\n",
       "      <td>0.473946</td>\n",
       "      <td>batch size : 60\\n image size 192 \\n loss funct...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_acc  valid_acc                                          param_str\n",
       "0   0.559442   0.319212  batch size : 60\\n image size 60 \\n loss functi...\n",
       "1   0.607131   0.383853  batch size : 60\\n image size 96 \\n loss functi...\n",
       "2   0.642834   0.448823  batch size : 60\\n image size 128 \\n loss funct...\n",
       "3   0.818625   0.557362  batch size : 60\\n image size 160 \\n loss funct...\n",
       "4   0.672038   0.473946  batch size : 60\\n image size 192 \\n loss funct..."
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_4_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that 160x160 images performed best in this test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this test, a variety of epochs will be tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving validation accuracy via data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating New Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
